\documentclass[12pt]{amsart}

\usepackage{tikz}
\usepackage{bbm}
\usetikzlibrary{3d,arrows,calc,positioning,decorations.pathreplacing,matrix} %,arrows.meta}

\usepackage{calligra,mathrsfs}
\usepackage[all]{xy}
\usepackage{float, comment}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amstext}
\usepackage{amsopn}
\usepackage{stmaryrd}
%\usepackage{mathrsfs} % allows \mathscr
\usepackage[mathscr]{eucal}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{graphicx} % allows \includegraphics{}s
\usepackage{tikz-cd}
\usepackage{scalerel}
\usepackage{microtype} % improves formattings
\usepackage[margin=1in,marginparwidth=0.8in, marginparsep=0.1in]{geometry}
\renewcommand{\baselinestretch}{1.2} % changes page formatting
\usepackage[pagebackref, bookmarks=true, bookmarksopen=true, bookmarksdepth=3,bookmarksopenlevel=2, colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, menucolor=blue, urlcolor=blue]{hyperref}
% \usepackage{newtxtext} % improves font appearance
\usepackage{tikz}
\usepackage{bbm}
\usepackage[all]{xy}
\usetikzlibrary{arrows,calc,positioning,decorations.pathreplacing} %,arrows.meta}

%Path relative to the main .tex file 
\graphicspath{ {./figures/} }

\newcommand{\blue}{\color{blue}}
\newcommand{\red}{\color{red}}

\numberwithin{equation}{section}
\newtheorem{Theorem}[equation]{Theorem}
\newtheorem{Proof}[equation]{Proof}
\newtheorem{Proposition}[equation]{Proposition} 
\newtheorem{Lemma}[equation]{Lemma}
\newtheorem{Open}[equation]{Open Question}
\newtheorem{Corollary}[equation]{Corollary}
\newtheorem{Conjecture}[equation]{Conjecture}
\newtheorem{Specialthm}{Theorem}
\newtheorem{Question}{Question}

\theoremstyle{definition}
\newtheorem{Remark}[equation]{Remark}
\newtheorem{Example}[equation]{Example}
\newtheorem{Definition}[equation]{Definition}

\numberwithin{figure}{section}

\def\la{\langle}
\def\ra{\rangle}
\def\ttimes{\widetilde{\times}}
\def\tbox{\widetilde{\boxtimes}}
\def\bbox{{\boxtimes}}
\def\O{\mathcal{O}}
\def\K{\mathcal{K}}
\def\bG{\mathbb{G}}
\newcommand{\gr}{\mathrm{gr}}
\newcommand{\wt}{\text{wt}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\fsl}{\mathfrak{sl}}
\newcommand{\fg}{\mathfrak{g}}
\newcommand{\fn}{\mathfrak{n}}
\newcommand{\bk}{{\mathbbm k}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\bN}{\mathbb{N}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\bfC}{{\mathbf{C}}}
\newcommand{\bfD}{{\mathbf{D}}}
\newcommand{\bfI}{{\mathbf{I}}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\sW}{\mathscr{W}}
\newcommand{\sX}{\mathscr{X}}
\newcommand{\sY}{\mathscr{Y}}
\newcommand{\sZ}{\mathscr{Z}}

\newcommand{\hs}{\heartsuit}
\newcommand{\bul}{\bullet}
\newcommand{\ga}{\gamma}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}

%Commands for Lecture 12
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\pt}{\operatorname{pt}}
\newcommand{\codim}{\operatorname{codim}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\spn}{\operatorname{span}}

%Commands for Lecture 14
\newcommand{\on}[1]{\operatorname{#1}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\Gr}{\on{Gr}}
\newcommand{\TeL}{\on{TL}}
\newcommand{\Rcheck}{\breve{R}}
\newcommand{\Stil}{\tilde{S}}
\usepackage{tikzit}
\input{tikzit_styles.tikzstyles}

%Commands for Lecture 13, 15
\newcommand{\GS}{\operatorname{GS}}
% \newcommand{\GL}{\mathrm{GL}}
\newcommand{\Fl}{\operatorname{\mathscr{F}\!\ell}}
% \newcommand{\End}{\mathrm{End}}
\newcommand{\Lie}{\operatorname{Lie}}
\newcommand{\MO}{\operatorname{MO}}


%% code from mathabx.sty and mathabx.dcl
\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
	<5> <6> <7> <8> <9> <10>
	<10.95> <12> <14.4> <17.28> <20.74> <24.88>
	mathx10
}{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathAccent{\widecheck}{0}{mathx}{"71}
\DeclareMathSymbol{\shortminus}{\mathbin}{AMSa}{"39}

\DeclareRobustCommand{\SkipTocEntry}[5]{}

\newcommand{\arrtip}{latex'}

\begin{document}
\title{Notes on Schubert Calculus and Quantum Integrability}

\begin{abstract}
\end{abstract}

\maketitle

\setcounter{tocdepth}{1}

\tableofcontents

\section{Introduction}

\thispagestyle{empty}

Here is a template for a simple commutative diagram in tikz:
\begin{equation*}
\begin{tikzpicture}
[baseline=(current  bounding  box.center),thick,>=\arrtip]
\node (a) at (0,0) {$X'$};
\node (b) at (2.5,0) {$Y'$};
\node (c) at (0,-1.5) {$X$};
\node (d) at (2.5,-1.5) {$Y$};
\draw[->] (a) to node[above] {$f' $} (b);
\draw[->] (b) to node[right] {$h $} (d);
\draw[->] (a) to node[left] {$h' $}(c);
\draw[->] (c) to node[above] {$f $} (d);
\end{tikzpicture}
\end{equation*}

Here is a template for an elaborate commutative diagram in tikz:
\begin{equation*}
\begin{tikzpicture}[baseline=(current  bounding  box.center),thick,>=\arrtip]
\newcommand*{\ha}{1.6}; \newcommand*{\hb}{1.6}; \newcommand*{\hc}{1.6};
\newcommand*{\va}{-1.1}; \newcommand*{\vb}{-1.1}; \newcommand*{\vc}{-1.1};
\node (ab) at (\ha,0) {$X_\al'$};
\node (ad) at (\ha+\hb+\hc,0) {$Y_\al'$};
\node (ba) at (0,\va) {$X'$};
\node (bc) at (\ha+\hb,\va) {$Y'$};
\node (cb) at (\ha,\va+\vb) {$X_\al$};
\node (cd) at (\ha+\hb+\hc,\va+\vb) {$Y_\al$};
\node (da) at (0,\va+\vb+\vc) {$X$};
\node (dc) at (\ha+\hb,\va+\vb+\vc) {$Y$};
\draw[->] (ab) to node[above] {$\phi' $} (ad);
\draw[->] (ab) to node[above] {$ $} (ba);
\draw[->] (ab) to node[left,pos=.8] {$\psi' $} (cb);
\draw[->] (ad) to node[above] {$ $} (bc);
\draw[->] (ad) to node[right] {$\psi $} (cd);
\draw[->] (ba) to node[above] {$ $} (da);
\draw[->] (cb) to node[above,pos=.2] {$\phi $} (cd);
\draw[->] (cb) to node[above] {$ $} (da);
\draw[->] (cd) to node[above] {$ $} (dc);
\draw[->] (da) to node[above,pos=.6] {$f $} (dc);
\draw[-,line width=6pt,draw=white] (ba) to  (bc);
\draw[->] (ba) to node[above,pos=.75] {$f' $} (bc);
\draw[-,line width=6pt,draw=white] (bc) to  (dc);
\draw[->] (bc) to node[right,pos=.2] {$h $} (dc);
\end{tikzpicture}
\end{equation*}


\section{Lecture 1 (Allen Knutson)}

Let $V$ be a $k$-plane in $\C^n$ with basis represented as a $k\times n$ matrix with basis elements as row vectors. Put this matrix into Reduced Row Echelon Form and consider left action by $GL_k(\C)$ and right action by upper triangular matrices to get an open subgroup of \textit{right word row operations}.

\begin{Theorem}
	A matrix $\text{Mat}_n(\C)$ acted on the left by $GL_k(\C)$ downward row operations and  on the right by upper triangular matrices rightward column operations, that is,
	$$\begin{tikzpicture}
		\node (a) at (.3,.3) {$*$};
		\node (b) at (.7,.7) {$0$};
		\draw [-] (.9,.1) to (.1,.9);
		\draw[-] (0,0) to (0,1);
		\draw[-] (1,0) to (1,1);
		\draw[-] (0,0) to (.1,0);
		\draw[-] (0,1) to (.1,1);
		\draw[-] (.9,0) to (1,0);
		\draw[-] (.9,1) to (1,1);
		\node (c) at (2.5,.5) {$\circlearrowright$Mat$_n(\C)\circlearrowleft$};
		\node (a) at (4.3,.3) {$0$};
		\node (b) at (4.7,.7) {$*$};
		\draw [-] (4.9,.1) to (4.1,.9);
		\draw[-] (4,0) to (4,1);
		\draw[-] (5,0) to (5,1);
		\draw[-] (4,0) to (4.1,0);
		\draw[-] (4,1) to (4.1,1);
		\draw[-] (4.9,0) to (5,0);
		\draw[-] (4.9,1) to (5,1);
	\end{tikzpicture}$$
	has one orbit for each partial permutation matrix. This is the \textbf{Bruhet decomposition} of the matrix.
\end{Theorem}

\begin{Definition}
	A matrix \textbf{Schubert Variety} is $\overline{X_{\pi}}:=\overline{B_-\pi B_+}$ where $\pi$ is the permutation matrix.
\end{Definition}

\begin{Theorem}
	$\overline{X_\pi}$ is the set of $n\times n$ matrices, $M$, such that for all $i,j\in[n]$, the $i\times j$ submatrix of $M$ is less than or equal to the $i\times j$ submatrix of $\pi$. That is, the determinants summarized by these conditions generate a prime ideal whose vanishing set is $\overline{X_\pi}$.
\end{Theorem}

As an example, consider $\pi=3142$ pictured below:

\begin{center}
	\begin{tikzpicture}
		\node (40) at (0,.5) {$2$};
		\node (30) at (0,1.5) {$4$};
		\node (20) at (0,2.5) {$1$};
		\node (10) at (0,3.5) {$3$};
		\node (21) at (1,2.5) {$1$};
		\node (11) at (1,3.5) {$0$};
		\node (42) at (2, .5) {$1$};
		\node (32) at (2,1.5) {$*$};
		\node (12) at (2,3.5) {$0$};
		\node (13) at (3,3.5) {$1$};
		\node (34) at (4,1.5) {$1$};
		\draw[-] (.5,0) to (.5,4);
		\draw[-] (4.5,0) to (4.5,4);
		\draw[-] (.5,0) to (4.5,0);
		\draw[-] (.5,4) to (4.5,4);
		\draw[->] (2.5,.5) to (4.3,.5);
		\draw[->] (1,2) to (1,.5);
		\draw[->] (1.5,2.5) to (4,2.5);
		\draw[->] (4,1) to (4,.3);
		\draw[->] (3,3) to (3,.3);
		\draw[->] (3.5,3.5) to (4.3,3.5);
	\end{tikzpicture}
\end{center}
The arrows are referred to as \textbf{death rays} since each leading one eliminates the entries to the right of and below it. In this example we have that $$m_{11}=m_{12}=0=\det\left ( \begin{array}{cc} m_{21} & m_{22} \\ m_{31} & m_{32}  \end{array}\right )$$ and the associated \textbf{Rothe diagram} is $$\left [ \begin{array}{cc} 0 & 0 \\ & *\end{array}\right ]$$

Two natural questions arise. First, how big is $\overline{X_\pi}$? We see that \begin{align*}
	\dim\overline{X_\pi}&=\dim(B_-\pi B_+) \\
	&= \dim(B_-\times B_+)-\dim(\text{stab}(\pi))\\
	&=\text{the number of entries crossed out in the death ray diagram}\\
	&=\dim T_\pi(B_-\pi B_+)\\
	&=\dim(b_-\pi+\pi b_+)
\end{align*}
Where $b_-$ and $b_+$ are lie algebras. Hence the codimension of $\overline{X_\pi}$ is the number of entries in the Rothe diagram.

\begin{Theorem}
	The only essential rank conditions are at the southeast corners of the Rothe diagram.
\end{Theorem}

The second question is what is the volumn of $\P(\overline{X_\pi})$?
Considering the degree as a projective variety, we get the following axioms for $Y\subseteq\P(V)$ defined by some homogeneous ideal.
\begin{enumerate}
	\item[(0)] The degree of $p^1$ is 1.
	\item If $Y$ is reducible, that is the ideal is not prime, such that $Y=Y_1\cup Y_2\cup\cdots\cup Y_k$ and $I\subseteq P_i$ is minimal, then the degree of $Y$ is the sum over the top dimensional components of the product of the multiplicity of $Y_i$ and the degree of $Y_i$.
	\item If $W\subseteq V$ is a hyperplane and $\P(W)\supseteq Y$ then the degree of $Y$ in $\P(V)$ is equal to the degree of $Y$ in $\P(W)$.
	\item If $W\subseteq V$ is a hyperplane and Y is reduced and irreducible, that is I is prime and $Y\subseteq \P(W)$, then the degree of $Y$ in $\P(V)$ is equal to the degree of $Y\cap\P(W)$ in $\P(W)$.
	
\end{enumerate}

What is the degree of $\P(\overline{X_\pi})$? Consider the base case where $$\pi=w_0^{(n)}=
\vcenter{\hbox{\begin{tikzpicture}
			\node at (.2,.2) {1};
			\node at (.8,.8) {1};
			\node at (.4,.4) {$\cdot$};
			\node at (.5,.5) {$\cdot$};
			\node at (.6,.6) {$\cdot$};
			\draw[-] (0,0) to (0,1);
			\draw[-] (0,0) to (.2,0);
			\draw[-] (0,1) to (.2,1);
			\draw[-] (1,0) to (1,1);
			\draw[-] (.8,0) to (1,0);
			\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}$$.

After eliminating entries via death rays we see that
$\overline{X_\pi}=\left \{ M: \vcenter{\hbox{\begin{tikzpicture}
			\node at (.2,.8) {0};
			\node at (.8,.2) {*};
			\draw[-] (.2,.2) to (.8,.8);
			\draw[-] (0,0) to (0,1);
			\draw[-] (0,0) to (.2,0);
			\draw[-] (0,1) to (.2,1);
			\draw[-] (1,0) to (1,1);
			\draw[-] (.8,0) to (1,0);
			\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}\right \}$
where the $0$'s in the upper left of the matrix aligns with axiom 2 and the free variables in the lower left align with axiom 3. This gives us that $\deg(\overline{X_\pi})=1$.

If $\pi\neq w_0^{(n)}$ pick $i\in[n]$ least such that $\pi(i)\neq w_0^{(n)}(i)=n+1-i$. Then $W:=\{ M: m_i\pi(i)=0\}$ and $$\overline{X_\pi}\cap W=\overline{X_\pi}\cap\left\{ \vcenter{\hbox{\begin{tikzpicture}
			\node at (0,0) {$i$};
			\node at (1,1.1) {$\pi(i)$};
			\node at (.6,.4) {$0$};
			\draw[-] (.2,.8) to (.2,-.8);
			\draw[-] (.2,-.8) to (1.8,-.8);
			\draw[-] (1.8,-.8) to (1.8,.8);
			\draw[-] (1.8,.8)to (.2,.8);
			\draw[-] (1,0) to (1,.8);
			\draw[-] (.2,0) to (1,0);
\end{tikzpicture}}}\right\}\circlearrowleft B_-\times B_+ \text{ invariant}$$ which is the union of $\overline{X_{\pi'}}$ over certain $\pi'$ none of which are strictly partial permutations and all multiplicities are $1$.

\begin{Definition}
	A \textbf{pipe dream} for $\pi$ is a diagram $$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (5,4);
				\draw[-] (5,4) to (5,0);
				\draw[-] (5,0) to (1,0);
				\draw[-] (1,0) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (...) at (3.5,4.5) {$\cdots$};
				\node (n) at (4.5,4.5) {$n$};
				\node (p1) at (0,3.5) {$\pi(1)$};
				\node (p2) at (0,2.5) {$\pi(2)$};
				\node (p) at (0,1.5) {$\hdots$};
				\node (pn) at (0,.5) {$\pi(n)$};
				\draw[-] (2,4) to (2,0);
				\draw[-] (3,4) to (3,0);
				\draw[-] (4,4) to (4,0);
				\draw[-] (1,1) to (5,1);
				\draw[-] (1,2) to (5,2);
				\draw[-] (1,3) to (5,3);
				\draw[-] (1,4) to (5,4);
	\end{tikzpicture}}}$$
	where each box is filed in with one of two tiles: crosses $\vcenter{\hbox{\begin{tikzpicture}
				\node at (0,.5) {j};
				\node at (.5,1) {i};
				\node at (1,.5) {j};
				\node at (.5,0) {i};
				\draw[-] (.2,.2) to (.2,.8);
				\draw[-] (.2,.8) to (.8,.8);
				\draw[-] (.8,.8) to (.8,.2);
				\draw[-] (.8,.2) to (.2,.2);
				\draw[-] (.2,.5) to (.8,.5);
				\draw[-] (.5,.2) to (.5,.8);
	\end{tikzpicture}}}$ when $i\leq j$ and elbows $\vcenter{\hbox{\begin{tikzpicture}
				\node at (0,.5) {i};
				\node at (.5,1) {i};
				\node at (1,.5) {j};
				\node at (.5,0) {j};
				\draw[-] (.2,.2) to (.2,.8);
				\draw[-] (.2,.8) to (.8,.8);
				\draw[-] (.8,.8) to (.8,.2);
				\draw[-] (.8,.2) to (.2,.2);
				\draw (.2,.5) arc[start angle=-90, end angle=0, radius=.3];
				\draw (.5,.25) arc[start angle=180, end angle=90, radius=.3];
	\end{tikzpicture}}}$ when $i\neq j$.
\end{Definition}

\begin{Theorem}
	The degree of $\overline{X_\pi}$ is the number of pipe dreams of $\pi$.
\end{Theorem}
For a torus $T\cong (\C^x)^N$ and $Y\subseteq V)\circlearrowleft T$ where $Y$ is a $T$-invariant subvariety and $V$ is a $T$-representation can soup up the degree to a $T$-equivariant cohomology class. 

Our above axioms hold from above with the exception of axiom 2 which can be rewritten at follows: \begin{enumerate}
	\item[(2)] $[Y\subseteq V]$ equals the weight of $T(V/W)[Y\subseteq W]$ for $T\in T^*$. The $T^*$ weight lattice is given by Hom$(T,\C^x)\cong\Z^N$ such that for $\Lambda=(\lambda_1,\ldots,\lambda_N)\in\Z^N$ and $t=(t_1,\ldots,t_N)\in(\C^x)^N$, $\Lambda\cdot t=\prod\limits_{i=1}^N t_i^{\lambda_i}$. Then $[Y\subseteq V]\in\text{Sum}(T^*)\cong\Z[Y_1,\ldots,Y_n]$.
\end{enumerate}

\begin{Definition}
	The \textbf{Double Schubert Polynomial} is $S_\pi(X,Y)=[\overline{X_\pi}\subseteq\text{Mat}_n]$ with respect to $T\times T\circlearrowright\text{Mat}_n$ such that $\overline{S_\pi}(X,Y)=\sum\limits_{\text{p}}\prod\limits_{\text{c}}(X_{\text{row}}-Y_{\text{col}})$ where $p$ stands for pipe dreams for $\pi$ and $c$ represents crosses. 
\end{Definition}
Consider the possible pipe dreams for $\pi=132$.
\begin{center}
	$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (4,4);
				\draw[-] (4,4) to (4,1);
				\draw[-] (4,1) to (1,1);
				\draw[-] (1,1) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (3) at (3.5,4.5) {$3$};
				\node (p1) at (0,3.5) {$1$};
				\node (p2) at (0,2.5) {$3$};
				\node (p3) at (0,1.5) {$2$};
				\draw[-] (2,4) to (2,1);
				\draw[-] (3,4) to (3,1);
				\draw[-] (4,4) to (4,1);
				\draw[-] (1,1) to (4,1);
				\draw[-] (1,2) to (4,2);
				\draw[-] (1,3) to (4,3);
				\draw[-] (1,4) to (4,4);
				\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
				\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
				\draw (2,3.5) arc[start angle=-90, end angle=0, radius=.5]; %12
				\draw (2.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
				\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw[-] (1,2.5) to (2,2.5); %21
				\draw[-] (1.5,3) to (1.5,2);
				\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
				\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
				\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
				\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
				\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
				\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
	\end{tikzpicture}}}$
	\hspace{10mm} and \hspace{10mm}
	$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (4,4);
				\draw[-] (4,4) to (4,1);
				\draw[-] (4,1) to (1,1);
				\draw[-] (1,1) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (3) at (3.5,4.5) {$3$};
				\node (p1) at (0,3.5) {$1$};
				\node (p2) at (0,2.5) {$3$};
				\node (p3) at (0,1.5) {$2$};
				\draw[-] (2,4) to (2,1);
				\draw[-] (3,4) to (3,1);
				\draw[-] (4,4) to (4,1);
				\draw[-] (1,1) to (4,1);
				\draw[-] (1,2) to (4,2);
				\draw[-] (1,3) to (4,3);
				\draw[-] (1,4) to (4,4);
				\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
				\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
				\draw[-] (2.5,4) to (2.5,3); %12
				\draw[-] (2,3.5) to (3,3.5);
				\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
				\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,2.5) arc[start angle=-90, end angle=0, radius=.5]; %21
				\draw (1.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
				\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
				\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
				\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
				\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
				\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
	\end{tikzpicture}}}$
\end{center}
\vspace{5mm}
Frome these pipe dreams we see that the Double Schubert Polynomial is $S_{132}=(X_2-Y_1)+(X_1-Y_2)$.

\section{Lecture 2 (Allen Knutson)}

\section{Lecture 3 (Paul Zinn-Justin)}

\section{Lecture 4 (Paul Zinn-Justin)}

\section{Lecture 5 (Allen Knutson)}

% 6/7/22, Allen Knutson (Lecture 5 of 18 total)
% LaTeXed by Claire Mirocha claire_mirocha@berkeley.edu

Recall that matrix Schubert varieties are of the following form (where $\pi$ is a permutation matrix): $$\overline{X}_{\pi} \coloneqq \overline{\vcenter{\hbox{\begin{tikzpicture}
\node at (.2,.2) {*};
\node at (.8,.8) {0};
\draw[-] (.2,.8) to (.8,.2);
\draw[-] (0,0) to (0,1);
\draw[-] (0,0) to (.2,0);
\draw[-] (0,1) to (.2,1);
\draw[-] (1,0) to (1,1);
\draw[-] (.8,0) to (1,0);
\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}} \pi 
\vcenter{\hbox{\begin{tikzpicture}
\node at (.2,.2) {0};
\node at (.8,.8) {*};
\draw[-] (.2,.8) to (.8,.2);
\draw[-] (0,0) to (0,1);
\draw[-] (0,0) to (.2,0);
\draw[-] (0,1) to (.2,1);
\draw[-] (1,0) to (1,1);
\draw[-] (.8,0) to (1,0);
\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}} = \overline{B_- \pi B_+} \subset \text{Mat}_n$$

For a linear representation $V$, the action $T \curvearrowright (V \supset X)$ gives us $[X \subset V] \in \text{Sym}T^{\ast} \simeq \Z[y_1, \dots, y_d]$.

Importantly, note that we can \textit{always} split $V$ as a direct sum of irreducible $T$-representations: \\
$$V \cong \bigoplus_{\text{weights }\lambda} \C_{\lambda}^{\oplus m_{\lambda}} \; \text{ for some multiplicities } m_{\lambda} \in \bN$$


Recall also our pipe dream formula, from yesterday's definition of the double Schubert polynomial $S_{\pi}$:
$$S_{\pi}(x_1, \dots, x_n, y_1, \dots, y_n) = [\overline{X_{\pi}} \subset \text{Mat}_n] = \sum_{\text{(pipe dreams for } \pi)} \prod_{\text{(crosses)}}x_{\text{row}} - y_{\text{col}}$$

\vspace{1em}

\begin{Definition}[Multigraded Hilbert series]
For a vector space $V$ of dimension $n$ (not necessarily equal to $\dim T)$, define $R \coloneqq \text{Fun}(V) \cong \C[z_1, \dots, z_n]$. Then the multigraded Hilbert series of $R$ is the formal sum
$$ h_R \coloneqq \sum_{\text{weights } \lambda \text{ of } T} \dim_{\C}(R_{\lambda})\, e^{\lambda}  \quad \in \mathbb{Z}[e^{\pm y_1}, \dots, e^{\pm y_d}]$$
where $R_{\lambda}$ is the $\lambda$-weight space of $R$.
\end{Definition}

Note that we have $h_{\oplus R_i} = \oplus h_{R_i}$.

To ensure the dimensions of the above weight spaces are finite, we impose the ``attractive condition" (we'll call it this, because we like it) that all $\lambda_i$ must lie in an open half-space.

\begin{Example}
We have the weight $\text{wt}(z_1^2 z_3) = -2 \lambda_1 - 1 \lambda_3$ (note that the coefficients are negative because we are acting on the dual space).
\end{Example}

\begin{Example}
For $n=1$, we have $\C[z_1] = \text{Fun}(V)$. So $h_R = \sum_{k=0}^{\infty} e^{-k \lambda_1} = \frac{1}{1-e^{-\lambda_1}}$.
\end{Example}

\begin{Example}
For general $n$, using the calculation directly above, we obtain $\C[z_1, \dots, z_n] \cong \C[z_1] \otimes \dots \otimes \C[z_n]$. So $h_R = \Pi_{i=1}^{n}  \frac{1}{1-e^{-\lambda_i}}$.
\end{Example}

\begin{Definition}[Multigraded / $T$-equivariant module]
If $R \curvearrowright M$, we say that $M$ is a multigraded (i.e. $T$-equivariant) module if:
\begin{itemize}
    \item $T \curvearrowright M$ (i.e. $M = \oplus_{\lambda \in T^{\ast}} M_{\lambda}$)
    \item $r \in R_{\lambda}, m \in M_{\mu} \implies rm \in M_{\lambda + \mu}$
\end{itemize} \end{Definition}

\begin{Definition}[Multigraded Hilbert series of an $R$-module $M$]
For $M$ a finitely generated $R$-module, we define 
$$ h_M \coloneqq \sum_{\text{weights } \lambda \text{ of } T} \dim(M_{\lambda}) \, e^{\lambda} $$
\end{Definition} 

Note from the definition above that the multigraded Hilbert series is so named because it is not graded by $\mathbb{Z}$ or $\mathbb{N}$, but by the weight lattice for $T$. Being multigraded is the same as having a torus action.

\begin{Example}
If $M = Rm$ (a free $R$-module with one generator), and $\text{wt}(m) = \lambda_m$, then $h_M = e^{\lambda_m} h_R$.
\end{Example}

A key example is the case $M = R/I$,  where $I$ is a $T$-invariant ideal, and $X = V(I)$. This motivates the next definition: notice that if $I=0$ (so $X$ is the entire space $V$), then we'd like $[V \subset V]$ to be 1. Directly above, though, we've already computed this to be a sum not equal to 1. The ``$K$-theoretical version" here will fix this issue.

\begin{Definition}
Letting $X = V(I)$, we have $[X \subset V]_K \coloneqq \frac{h_{R/I}}{h_R}$.
\end{Definition}

\begin{Theorem}
$[X \subset V]_K$ is a Laurent polynomial in $\{e^{\lambda}\}$.
\end{Theorem}
\begin{proof}
Sketch: If $R/I$ is a finitely generated module over a Noetherian ring $R$, and $I = (f_1, \dots, f_n)$, then there is a finite free resolution of $R/I$:
$$ 0 \to \dots \to \oplus_i R[\mu_i] \to R \to R/I \to 0 $$
So, this free resolution terminates, and the Hilbert series we want is an alternating sum of Hilbert series corresponding to the terms in the free resolution. Using that the series ``commutes with direct sum," and the fact that we've already computed series for single terms, we obtain a finite Laurent polynomial.
\end{proof}

\begin{Example}
If $X \subset V$ is a linear subspace, with $V = X \oplus X'$, then $[X \subset V]_K = \prod_{\mu \in X'}(1-e^{-\mu}) \in \Z[e^{\pm \mu}]$, whereas $[X \subset V] = \prod_{\mu \in X'} \mu \in \text{Sym}T^{\ast} = \Z[y_1, \dots, y_n]$.
\end{Example}

\noindent Next, let's check which axioms for $[X \subset V]$ are still satisfied by $[X \subset V]_K$:
\begin{enumerate}
    \item[\checkmark (0)] $[\{0\} \subset \{0\}]_K = 1$
    \item [\checkmark (2)] For a hyperplane $W = \{f=0\}$ with $X \subset W \subset V$, $[X \subset V]_K \coloneqq \frac{h_X}{h_V} = \frac{h_X}{h_W} \frac{h_W}{h_V} = [X \subset W]_K [W \subset V]_K$.
    \item[\checkmark (1)] With the setup above, and $X \subset V$, $X \not \subset W$, and $X$ reduced and irreducible, recall that $X = V(I)$ for $I$ a prime ideal $\iff$ $R/I$ is an integral domain.
    
    Letting $h_{X \cap W} \coloneqq h_{R/(I+(f))}$, we have exact sequence
    $$ 0 \to (R/I)f \hookrightarrow R/I \twoheadrightarrow R/(I + (f)) \to 0 $$
    This gives us an injection
    $$ 0 \to R/I \stackrel{\cdot f}{\to} (R/I)f \to 0 $$
    The second map $\cdot f$ above is an isomorphism of $R$-modules, but not in the multigraded sense. To fix this, we must introduce a shift by the weight $[e^{\wt(f)}]$, with $\wt(f) = -\wt(V(f)/W)$.
    Then, we indeed have $[X \subset V]_K = [X \cap W \subset W]_K$, and the axiom holds.
    
    \item[$\bigtimes$ \, (3)] This axiom no longer holds for $[X \subset V]_K$. For example, consider $R = \C[x,y]$, and $I = (x^2 - y^2)$. This is not a prime ideal; we can form quotients by $(x-y)$ or $(x+y)$, obtaining the following short exact sequence of    homogeneous graded $R$-modules:
    $$ 0 \to R/(x^2-y^2) \to R/(x-y) \oplus R/(x+y) \to R/(x,y) \to 0 $$
\centerline{\includegraphics[width=4in]{5.1.jpeg}}

\end{enumerate}
\vspace{1em}
\textbf{Question:} How do we relate $[X \subset V]$ and $[X \subset V]_K$?
\begin{Theorem}
Replace $\lambda$ by $\epsilon \lambda$, and take the leading term. That is:
$$ \lim_{\epsilon \to 0} \left( \frac{[X \subset V]_K}{\epsilon^{\text{codim}_v X}} \right) = [X \subset V] $$
\end{Theorem}

A last definition, which will soon be relevant:

\begin{Definition}[Subword complex]
If $Q$ is a word in the generators of a Coxeter group $W$, with $w \in W$, the subword complex $\Delta(Q,w)$ is a simplicial complex with vertices corresponding to the elements of $Q$.

A subword $F \subset Q$ is called a facet (i.e. a maximal face) precisely when $Q \setminus F$ is a reduced word for $w$.
\end{Definition}

\begin{Example}
Let $r_1$ be the transposition $(12) \in S_n$. Then $\Delta(121, r_1)$ (where $121$ is shorthand for $r_1 r_2 r_1$) is the simplicial complex pictured: \vspace{1em}

\centerline{\includegraphics[width=2in]{5.2.jpeg}}

Note that we index faces and vertices according to ``missing" letters in $Q$, and the complex above is homotopy equivalent to a point. Note also that the unpictured bottom edge, $-2-$ (i.e., $(23)$ in cycle notation), is \textit{not} a facet, because $r_2 = (23)$ is not a reduced word for $r_1$, whereas the other edges yield.
\end{Example}

\section{Lecture 6 (Allen Knutson)}
This lecture is split into two parts.  The first is a continuation of the previous lecture, leading up to an equivariant $K$-theory version of the AJS/Billey formula.  The second is a discussion of $G$-equivariant cohomology from the ground up.

\subsection{The subword complex and equivariant $K$-theory} Recall that given a word $Q$ in the primitive generators of a Coxeter group $W$, and some element $w\in W$, we can build the subword complex $\Delta(Q,w)$. The following theorem gives us a sense of what these look like:

\begin{Theorem}[Knutson-Miller '05] Let $\ell(w)$ denote the length of $w$. Then:
\begin{enumerate}
    \item $\dim \Delta(Q,w) = \# Q - \ell(w) - 1$.
    \item $\Delta (Q,w)$ is always homeomorphic to a ball or a sphere. It is also a $\Delta(Q,w)$ is a \textbf{shellable}  simplicial complex.  
    \item $\partial \Delta(Q,w) = \bigcup_{ w' > w} \Delta(Q,w')$.
\end{enumerate}
\end{Theorem}

We'll mention one other result that tells us something about the combinatorics of these complexes, namely about the links to their faces.

\begin{Example}
First, what's the link of a stratum in a stratified space?  Well, it's the intersection of the boundary of a small open neighborhood of that stratum.  Here's a picture of a link (red) of a stratum (blue), together with the ``combinatorialized'' version of the link available to a simplicial set:
\begin{center}
\includegraphics[width=4in]{6.1.png}
\end{center}
\end{Example}

The result will be stated using the following terminology:
\begin{Definition}
The \textbf{Mobius function} on the faces $F$ of a simplicial complex is
\[ \mu(F) := 1 - \chi(\textup{link of }F)\]
\end{Definition}

\begin{Theorem}
If $\Delta$ is a shellable ball or sphere, then 
    \[ \textup{link}(F) \cong \begin{cases} \textup{hemisphere} & \textup{for $F$ an exterior face}\\
    \textup{sphere} \cong S^{\textup{codim}{F} - 1} & \textup{for $F$ an interior face}\end{cases}\]
Translated, this gives:
\[\mu(F) = \begin{cases} 0 & \textup{for $F$ an exterior face}\\
   (-1)^{\text{codim}(F)}  & \textup{for $F$ an interior face}\end{cases}\]
In our case, where $\Delta = \Delta(Q,w)$, and is thus a shellable ball or sphere, this result implies that $\mu(F) = \pm1$ if $Q \setminus F$ doesn't contain a reduced word $w' \subset w$, and is 0 otherwise.
\end{Theorem}


OK, back to Schubert stuff, where we'll use some of the above terminology. Recall that given $v\in W$ and a reduced word $Q$ for $v$, AJS/Billey gives us a formula

\[ [ X_0^v \cap X_w] = \sum_{\textup{reduced subexpression }R\subseteq Q\\ = \textup{facets of $\Delta(Q,v)$}} stuff \quad \in H_T^*(X_0^v)\]

This is a statement in equivariant cohomology. We will see that there is also an analogous formula in equivariant $K$-theory!  To get there, the above language of the subword complex will be useful, in light of the following result:

\begin{Theorem}[Knutson] There exists a $T$-equivariant degeneration of the Kazhdan-Lusztig variety $X_0^v \cap X_w$ to the Stanley-Reisner variety of the subword complex:
\[ SR(\Delta(Q,w)) := \bigcup_{\textup{facets $F$ of }\Delta(Q,w)} \mathbb{C}^F \quad \subseteq \mathbb{C}^Q\]
\end{Theorem}

The fact that the degeneration is $T$-equivariant means that it drags along equivariant cohomology and $K$-theory classes. So in particular, this result implies the following promised $K$-theory version of AJS/Billey:
\begin{Theorem}[Graham-Willems]
Given $v\in W$ and a reduced word $Q$ for $v$,
\[ [ X_0^v \cap X_w]_K = \sum_{\textup{interior facets of $\Delta(Q,v)$}} (-1)^{|R|-\ell(w)}\Big(\prod_{q\in Q}r_q\cdot  \widehat{(1-e^{-\alpha_q})}\Big)\cdot 1 \quad \in K_T(X_0^v)\]
where the sum is now over subwords $R\subseteq Q$ such that $R$ contains a reduced word for $w$, but not for any $w' > w$; the notation $\widehat{(1-e^{-\alpha_q})}$ means that we only include this expression in the product if $q\in R$. 
\end{Theorem}

The above was about an $T$-equivariant $K$-theory class of an intersection inside the flag variety. Next, we'll have a formula for the $T\times T$-equivariant $K$-theory class of a matrix Schubert variety. Let's first give this a cool name:

\begin{Definition}
The \textbf{double Grothendieck polynomial} is 
\[ G_\pi(e^x, e^y) := [ \overline{X_\pi}]_K \in K_{T\times T}(\textup{Mat}_n) \cong K_{T\times T}(\textup{point}) = \mathbb{Z}[e^{\pm x_1}, \dots, e^{\pm x_n}, e^{\pm y_1}, \dots, e^{\pm y_n}]\]
\end{Definition}

\noindent It turns out that this also has a formula:

\begin{Theorem}[Fomin-Kirillov]
The double Grothendieck polynomial can be calculated as
\[G_\pi(e^x,e^y) = \sum_{\textup{possibly nonreduced pipe dreams for $\pi$}} (-1)^{\# \textup{extra $+$'s}} \prod_{+\textup{'s}} (1-e^{-x_{row} + y_{col}})\]
\end{Theorem}

\begin{Example}
For $\pi = 132$, recall from Lecture 1 that there are two reduced pipe dreams: 

\begin{center}
$\vcenter{\hbox{\begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw (2,3.5) arc[start angle=-90, end angle=0, radius=.5]; %12
\draw (2.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw[-] (1,2.5) to (2,2.5); %21
\draw[-] (1.5,3) to (1.5,2);
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}}}$
\hspace{10mm} and \hspace{10mm}
$\vcenter{\hbox{\begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw[-] (2.5,4) to (2.5,3); %12
\draw[-] (2,3.5) to (3,3.5);
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw (1,2.5) arc[start angle=-90, end angle=0, radius=.5]; %21
\draw (1.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}}}$
\end{center}
\vspace{5mm}

There is also one (properly) nonreduced pipe dream, with two crossings, which is resolved by the above reduced two:

\begin{center}
    \begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw[-] (2.5,4) to (2.5,3); %12
\draw[-] (2,3.5) to (3,3.5);
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw[-] (1,2.5) to (2,2.5); %21
\draw[-] (1.5,3) to (1.5,2);
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}
\end{center}

Therefore, by the Fomin-Kirillov formula, the double Grothendieck polynomial in this case is
\[ G_{132}(e^x, e^y) = (1-e^{-x_2 + y_1}) + (1-e^{-x_1 + y_2}) - (1-e^{-x_2 + y_1})(1-e^{-x_1 + y_2})\]
\end{Example}



\subsection{$G$-equivariant cohomology: what is it, really?}
Okay, changing gears! We've already seen some $G$-equivariant cohomology (and even some $G$-equivariant $K$-theory), but let's dive into the details a bit.

We all love integral cohomology. It's our favorite (contravariant) functor 
\[H^*: \frac{\{\textup{spaces, continuous maps}\}}{\textup{homotopy}} \to \textup{Rings}\]
Fixing a group $G$, we might wish to build a version of $H^*$, which we'll denote $H^*_G$, that goes like:
\[H_G^*: \frac{\{\textup{$G$-spaces, continuous $G$-equivariant maps}\}}{\textup{$G$-equivariant homotopy}} \to \textup{Rings}\]
In other words, we're shopping for some kind of topological invariant of $G$-spaces that is sensitive to the action itself (even though, confusingly, the action is not reflected in the notation ``$H_G^*$'' that we've chosen). Let's demand a few properties from $H_G^*$:
\begin{enumerate}
    \item if the $G$-action on $X$ is free, then $H_G^*(X) \cong H^*(X/G)$;
    \item if the $G$-space $C$ is contractible (but not necessarily $G$-equivariantly contractible), then $H_G^*(X \times C) \cong H_G^*(X)$, where the $G$-action on the product is the diagonal one.
\end{enumerate}
These are in fact a complete list of axioms of the theory.  Indeed, if $EG$ denotes any contractible space on which $G$ acts freely, then by (1) and (2) we have 
\[ H_G^*(X) \cong H_G^*(X\times EG) \cong H^*( (X\times EG)/G).\]
So we can calculate the equivariant cohomology of any $G$-space as the \textit{usual} cohomology of the \textbf{Borel mixing space} $(X\times EG)/G$ of the action. This space looks like an $X$-bundle over $EG/G =: BG$. 

To make use of this new invariant, we'll first need to build some $EG$'s. Let's do a few:

\begin{Example}
If $G=\Z$, we can take $E\Z := \mathbb{R}$ with the translation action. So $B\Z = S^1$.
\end{Example}

\begin{Example}
This will be the most important example for us. If $G=\mathbb{C}^\times$, we can take $E\mathbb{C}^\times := \mathbb{C}^\infty \setminus \{0\}$ with the diagonal action.  This space is contractible by a theorem in topology. By taking products, we get that we can take $E(\mathbb{C}^\times)^d := (E\mathbb{C}^\times)^d$. Another thing: since $B\mathbb{C}^\times \cong \mathbb{C}P^\infty$, we see that even the equivariant cohomology of a point can be huge: $H_{\mathbb{C}^\times}^*(\textup{point}) = H^*(\mathbb{C}P^\infty) = \mathbb{Z}[u], |u|=2$.
\end{Example}


\begin{Example}
If $G=GL_n\mathbb{C}$, we can take
\[ EGL_n\mathbb{C} := \{ n \times \mathbb{N} \textup{ matrices of rank $n$}\}\]
Repeatedly extracting the bottom row realizes $EGL_n\mathbb{C}$ as an iterated $(\mathbb{C}^\infty \setminus \{0\})$-bundle over $\mathbb{C}^\infty \setminus \{0\}$, and therefore it is contractible.

It's not so important that we know this example.  But since we do now, we can get a bunch of $EG$'s for free from the following simple observation: if $G\leq H$ is a subgroup, then $EH$ can serve as an $EG$!  So if $G \leq GL_n\mathbb{C}$ is any matrix group, we can just steal $EGL_n\mathbb{C}=:EG$.
\end{Example}

\begin{Remark}
If $G\leq H$ is a homotopy equivalence, then $H^*_G = H^*_H$. We will use this for a torus $T$ inside the Borels $B,B_-$.
\end{Remark}

\begin{Remark}
If $Y \subset X$ is a nice $G$-stable subset, then hopefully it's believable that it defines a class $[Y]_G \in H^*_G(X)$. We'll drop the subscript $G$ when it should be clear that something lives in equivariant cohomology. For example, both $[X_w^\circ]$ and $[X_w]$ refer to honest classes in $H_{B_-}^*(GL_n/B)$.
\end{Remark}

We'll calculate more with this later, but for now we'll take the $GL_n\mathbb{C}$-equivariant inclusion \fbox{$j: GL_n\mathbb{C} \hookrightarrow \textup{Mat}_n\mathbb{C}\simeq \textup{point}$} and extract a diagram that relates the classes we've encountered so far:

\begin{center}
\begin{tikzcd}
& & & \mathbb{Z}[x_1, \dots, x_n, y_1, \dots, y_n]\arrow[d,equals]\\
H^*_{B_-}(GL_n/B) & H^*_{B_-\times B}(GL_n)\arrow[l,equals] & H^*_{B_-\times
B}(\textup{Mat}_n\mathbb{C})\arrow[l,"j^*"'] \arrow[r,equals] & \overbrace{H^*_{T\times T}(\textup{point})}\\
\left[X_\pi\right] & \left[\overline{B_- \pi B}\right]\arrow[l,equals] & \left[\overline{\overline{B_- \pi B}}=: \overline{X_\pi}\right]\arrow[l,mapsto] & S_\pi (x,y)\arrow[l,equals]
\end{tikzcd}
\end{center}

Here is one more diagram that we can draw: for $v\in S_n$, there is the sequence of $T$-equivariant inclusions \fbox{$i_v: vB/B \hookrightarrow X_0^v \hookrightarrow GL_n/B$}, which gives

\begin{center}
    \begin{tikzcd}
    H_T^*(\textup{point}) \cong \mathbb{Z}[y_1, \dots, y_n]\arrow[d,equals] & & \\
    \overbrace{H^*_T(vB/B)} & H^*_T(X_0^v)\arrow[l,"i_v^*"'] & H_{T\simeq B_-}(GL_n/B)\arrow[l,"i_{X_0^v}^*"']\\
    \left[X_w\cap X_0^v\right]\big|_v \arrow[d,equals] & \left[X_w\cap X_0^v\right]\arrow[l,mapsto] & \left[X_w\right]\arrow[l,mapsto]\arrow[d,equals]\\
    S_w(x,y)|_{x_i := y_{v(i)}} & & S_w(x,y)
    \end{tikzcd}
\end{center}
This is a factorization of the map that just restricts to the $T$-fixed point $vB/B \in GL_n/B$.

\section{Lecture 7 (Paul Zinn-Justin)}

\section{Lecture 8 (Paul Zinn-Justin)}

\section{Lecture 9 (Allen Knutson)}

\section{Lecture 10 (Allen Knutson)}

\section{Lecture 11 (Paul Zinn-Justin)}

\section{Lecture 12 (Paul Zinn-Justin)}
    Define $f$ as follows:
\begin{align*}
    f:\Gr(k,n)&\to\Gr(k+1,n+1), \\
    V&\mapsto V\oplus\C
\end{align*}
where $\C$ is the $n$'th coordinate subspace and $\C^{n+1}=\C^n\oplus\C$.
Define
\begin{align*}
    T'=(\C^\times)^{n+1}\subset\GL(n+1)
\end{align*}
where $T=(\C^\times)^n$. The symmetrizer of $T'$ is $\Sym T'=\Z[y_1,\ldots,y_n,u]$. Then define
\begin{align*}
    f^\star:H_{T'}(\Gr(k+1,n+1))]\to H_{T'}(\Gr(k,n)).
\end{align*}
Then $D(u)=f^\star f_\star$. Note that $f^\star$ is surjective. Let $x\in H_{T'}^\star(\Gr(k,n))$ and $y\in H_{T'}(\Gr(k+1,n+1))$ where $x=f^\star y$. Then
\begin{align*}
    D(u)x = f^\star(f_\star f^\star y) = f^\star(yf_\star 1) = (f^\star f_\star 1)\times\C\in H_{T'}(\Gr(k,n)).
\end{align*}
Consider $\C^I$ where $I$ is a $k$-subset of $\{1,\ldots,n\}$. Then $[\mu]\stackrel{f_\star}{\mapsto}[\C^{I\cup\{n\}}]\stackrel{f^{-1}}{\to}[\C^I]$. Note that $\{\C^{I\cup\{n+1\}}\}\cap:\Gr(k,n)$, meaning this intersection is not transverse.

For $\varphi\in H_{T'}(\pt)=\Z[y_1\ldots,y_n,u]$, we have $\deg(\varphi)=\codim\Gr(k,n)\subset\Gr(k+1,n+1)$. We have that $T''\subset T'$ is the line of fixed points going through $\Gr(k,n)$ and $\C^{I_1I_2\cdots I_k}=\spn(e_{I_1},\ldots,e_{I_k},\sum e_j)$. Finally,
\begin{align*}
    \varphi(u) = \prod_{j\notin I}(u-y_i).
\end{align*}

Note that pipe dreams and puzzles have different lattice models. Pipe dreams have two labels ($0$, $1$) whereas puzzles have three labels ($0$, $1$, $10$). Considering the product of two Schubert classes $S^\lambda S^\mu$, we have
\begin{align*}
    S^\lambda S^\mu = \sum_\nu c_\nu^{\lambda\mu} S^\nu\in H_T(\pt).
\end{align*}
For all $w\in W_p/W$ (where $W_p=\cS_n\times\cS_{n-k}$ and $W=\cS_n$), we have
\begin{align*}
    S^\lambda|_wS^\mu|_w = \sum_\nu c_\nu^{\lambda\mu}S^\nu|_w.
\end{align*}
Our puzzle pieces are all the rotations of three triangles as well as one rhombus, called the equivariant tile, which may not be rotated: \ctikzfig{Tiles}

Encoding the partitions $\lambda$, $\mu$ and $\nu$ with $\{0,1\}$-strings, we fill in a puzzle corresponding to $c_\nu^{\lambda\mu}$ as follows: \ctikzfig{Puzzle}

Then $\Rcheck$ is a $9\times9$ matrix in $\End(\C^3\otimes\C^3)$.
\begin{align*}
    \tikz[baseline=6]{\draw(0,0)node[below]{$y_i$}--++(1,1);\draw(1,0)node[below]{$y_j$}--++(-1,1)} &=
    \tikz[baseline=16]{\draw(0,0)--++(1/2,1/2)--++(0,1/2)--++(-1/2,1/2);\draw(1/2,1)--++(1/2,1/2);\draw(1/2,1/2)--++(1/2,-1/2)} +
    (y_i-y_j)
    \tikz[baseline=6]{\draw(0,0)node[below]{$1$}--++(1,1)node[above]{$1$};\draw(1,0)node[below]{$0$}--++(-1,1)node[above]{$0$}} \\
    \cup &=
    \tikz[baseline=6]{\draw[>-](0,1)--++(1/2,-1/2);\draw[>-](1,1)--++(-1/2,-1/2);\draw[->](1/2,1/2)--++(0,-1/2)}
    \in \Hom(\C^3\otimes\C^3,\C^3)
\end{align*}
and $c_\nu^{\lambda\mu}=\langle\nu\mid\cup_1\cdots\cup_n\underbrace{\Rcheck\cdots\Rcheck(y_1-y_n)}_{\binom{n}{2}\text{ of these}}\mid\lambda\otimes\mu\rangle$. Note that if we glue the triangles along their $10$ labels they form a rhombus. Then assign a perpendicular unit vector to the $1$ labels in each tile as follows: \ctikzfig{TileVectors}

Next consider filling a triangle puzzle with the tiles. We have the following lemma.
\begin{Lemma}
    The boundary of a puzzle has vector sum zero.
\end{Lemma}
\begin{proof}
    Each tile has vector sum of zero, so a valid filling must have vector sum zero. When tiles meet internally, their vectors cancel so internal edges have vector sum zero. Thus, the vector sum of the boundary must also be zero; this means that each face of the triangle contains the same number of $0$'s and $1$'s.
\end{proof}

\section{Lecture 13 (Allen Knutson)}


Historical round up of the names whose work leads to understanding what the $6$ vertex puzzles were solving:
\begin{itemize}
	\item (Jimbo/Drinfeld '80s): $R$-matrices from representation theory of quantized loop algebras $U_q(\delta[z^\pm])$
	\item (Nakajima '01): some representations of $U_q(\delta[z^\pm])$ acting on $K(\text{quiver schemes})$ (think $\text{quiver schemes} = \bigsqcup \text{ quiver varieties}$)
	\item (Varagnolo '01): same thing in cohomology
	\item (Maulik-Okounkov '12): $R$-matrices "from" quiver schemes
\end{itemize}

\begin{Example}
	$\text{T}^* \Gr(k, \C^n)$ are Nakajima quiver varieties
\end{Example}

Note that quiver varieties and cotangent bundles of manifolds are always symplectic manifolds.
But quiver varieties are cotangent bundles \textbf{only} as cotangent bundles of flag manifolds or their products.

We will be working in $H^*_{T\times \C^\times} (\text{T}^* \Gr(k, \C^n))$ where the $\C^\times$ factor acts by dilation on the fibers. Note that we have
\[
	H^*_{T\times \C^\times} (\text{T}^* \Gr(k,\C^n)) \cong H^*_{T\times \C^\times} (\Gr(k,\C^n)) \cong H^*_{T} (\Gr(k,\C^n)) [\hbar]
\]
since $\text{T}^* \Gr(k,\C^n)$ and $\Gr(k,\C^n)$ are homotopy equivalent.

So although we have the Schubert basis, we will be working with a different basis.
In particular, we will be using specific subvarieties in $\text{T}^* \Gr(k,\C^n)$ that are not the Schubert varieties. However, as we shall see, taking the leading term with respect to $\hbar$ in the new basis will correspond to taking the Schubert classes.

\begin{Definition}
	To a locally closed submanifold $A \subsetneq M$ (e.g. Schubert cells) we associate its conormal bundle $C_A M \subset \text{T}^* M$ defined by

	\begin{center}
		\begin{tikzcd}
			C_A M \arrow[r, phantom, sloped, "\subseteq"] \arrow[d, equals] & \text{T}^* M \arrow[d, equals] \\
			\{(m,\overrightarrow{v}) : m\in A, \overrightarrow{v}\perp \text{T}_m A\}                                                & \{(m,\overrightarrow{v}): m\in M,\overrightarrow{v} \in \text{T}_m^* M \}
		\end{tikzcd}
	\end{center}
\end{Definition}

Note that $\dim C_A M = \dim M$.

Recall that for a continuous map $f: M\to N$ we get a map $\text{T} f : \text{T} M \to \text{T} N$, but \textbf{not} a map $\text{T}^* f : \text{T}^* M \to \text{T}^* N$. We wish to rectify this as follows:
\begin{Definition}
	The "category" of ({\color{red} symplectic}) manifolds \& ({\color{red} Lagrangian}) correspondences has objects - compact oriented manifolds and  morphisms - $\Hom(M,N) := \{ \text{ oriented cycles } L\subseteq M \times N\}$.
	(cycles in the sense of formal linear combinations)
\end{Definition}

\begin{Example}
	To a function $f:M \to N$ we can assign its graph,
	\[ \text{graph}(f) = \{(m, f(m)) : m \in M\} \subseteq M \times N.
	\]
\end{Example}

We define composition in our "category" as follows:

\begin{center}
	\begin{tikzcd}
		&                         & L \star K \arrow[ld] \arrow[rd] &                         &   \\
		& L \arrow[ld] \arrow[rd] &                         & K \arrow[ld] \arrow[rd] &   \\
		M &                         & N                       &                         & P
	\end{tikzcd}
\end{center}
where $L\star K \coloneqq L \times_N K = \{ (m,p) \in M\times P: \exists n\in N, (m, n) \in L, (n,p) \in K\}$.

Note that although $L\star K$ works as a set, it might \textbf{not} be a submanifold, hence why we say "category" and only consider compositions when they make sense.

\textbf{Why is this "category" worth understanding?}

Consider the functor $H_*$ (or $H^*$) from the category of compact oriented manifolds to inner product spaces.

Note that the category of inner product spaces has a notion of transpose, while the category of compact oriented manifolds does not. We attempt to fix this by introducing our "category" which has a transpose $(L \subseteq M\times N) \mapsto (L^T \subseteq N\times M)$. In fact, we see that $H_*$ factors through our "category" in the following way:

\begin{center}
	\begin{tikzcd}
		\left \{ \parbox{8em}{compact oriented manifolds \& functions} \right \} \arrow[rrrr,"H_*(\text{or } H^*)"] \arrow[rrd, "\text{graph}(\cdot)"] &  &               &  & \left \{ \parbox{8em}{inner product spaces} \right \} \\
		&  & \left \{ \parbox{8em}{compact oriented manifolds \& correspondences} \right \} \arrow[rru,"\beta"] &  & (\beta_L : H^*(M) \to H^*(N)) \\
		&  & L\in \Hom(M, N) \arrow[rru, mapsto]            &  &
	\end{tikzcd}
\end{center}

Where to define $\beta_L$, we consider the projections:
\begin{center}
	\begin{tikzcd}
		& M\times N \arrow[ld, "\pi_M"'] \arrow[rd,"\pi_N"] &   \\
		M &                         & N
	\end{tikzcd}
\end{center}
so that
\[
	\beta_L(m) \coloneqq (\pi_N)_*([L] \cup \pi_M^*(m))
\]

To see when $\beta$ works well with compositions, we require that $\int_N (L\times P) \pitchfork (M\times K)$, i.e.
\begin{itemize}
	\item $L\times P$ intersects transversally with $M\times K$ in $M\times N\times P$
	\item the image of $(L\times P) \cap (M\times K)$ in $N$ under projection is generically finite-to-one
\end{itemize}
in which case $\beta_{L \star K} = \beta_{K} \circ \beta_{L}$.


\begin{Remark}
	\[
		(\beta_{\text{graph}(f)})^T = f_* : H_*(M) \to H_*(N)
	\]
	where $f:M \to N$ is a function and $(\cdot)^T$ denotes the transpose.
\end{Remark}

What Alan Weinstein focused on is {\color{red} symplectic} manifolds and {\color{red} Lagrangian} correspondences.

In such cases, $C_A M$ is Lagrangian and whenever \[
	\int_N (L\times P) \pitchfork (M\times K)
\] holds, then $L \star K$ is Lagrangian.

Much less obvious is that $L \star K$ is a Lagrangian variety even without the transversality conditions. (reference needed)

\begin{Question}
	Let $f : M \to N$, prove that the following diagram commutes:

	\begin{center}
		\begin{tikzcd}
			\text{T}^* N \arrow[r]           & \text{T}^* M           \\
			N \arrow[r,"(\text{graph}(f))^T"] \arrow[u,"\text{graph}(\eta_N)"] & M \arrow[u,"\text{graph}(\eta_M)"']
		\end{tikzcd}
	\end{center}
	where $\eta_N,\eta_M$ denote the zero section functions.
\end{Question}

\section{Lecture 14 (Paul Zinn-Justin)}

\subsection{Basic Definitions}

\begin{Definition}[Temperley-Lieb Algebra]
	Let $\tau$ be a complex number. The \textbf{Temperley-Lieb algebra} $\TeL_n(\tau)$ is generated by an identity $1$ and generators $e_1, \ldots e_{n-1}$ satisfying the relations
	\begin{itemize}
		\item $e_i^2 = \tau e_i$
		\item $e_i e_{i+1} e_i = e_i$
		\item $e_i e_j = e_j e_i, |i-j|>1$
	\end{itemize}
\end{Definition}

We can give a pictorial description of this algebra: we regard each generator $e_i$ as corresponding to a diagram
\ctikzfig{TLfig1}
and regard $\tau$ as corresponding to the ``fugacity of a bubble." We then multiply by composing vertically (with the rightmost element at the top), and ``popping" bubbles to obtain a factor of $\tau$:
\ctikzfig{TLfig2}

\begin{Example}[$\TeL_3(\tau)$]
	When $n=3$, we have generators $1 = $ \tikzfig{TL3gen1}, $e_1 = $ \tikzfig{TL3gene1}, and $e_2 = $ \tikzfig{TL3gene2}. We also obtain
	\[e_1 e_2 = \tikzfig{TL3e1e2}\]
	and 
	\[e_2 e_1 = \tikzfig{TL3e2e1},\]
	so that $\TeL_3(\tau)$ is $5$-dimensional.
\end{Example}



\begin{Proposition}
	The dimension of $\TeL_n$ is
	\[\dim \TeL_n = C_n = \frac{(2n)!}{n!(n+1)!},\]
	the $n$th Catalan number.
\end{Proposition}

\subsection{Temperley-Lieb Algebras and the Yang-Baxter Equation} We can reinterpret the Yang-Baxter equation through the lens of Temperley-Lieb algebras. Let $\tau = -(q+q^{-1}), a(u) = qu-q^{-1}u^{-1},$ and $b(u) = u-u^{-1}.$ We can then regard $\Rcheck_i$ as an element of the algebra obtained by adding $u^\pm$ and $v^\pm$ to $\TeL_n(\tau)$:
\[\Rcheck_i(u) = a(u) 1 + b(u) e_i \in \TeL_n(\tau)[u^{\pm}, v^{\pm}].\]
One can check that the equation
\[\Rcheck_i(u) \Rcheck_{i+1}(uv) \Rcheck_i(v) = \Rcheck_{i+1}(v) \Rcheck_{i}(uv) \Rcheck_{i+1}(u)\]
holds; we may thus interpret the Yang-Baxter equation as an identity in $\TeL_n(\tau)[u^{\pm}, v^{\pm}].$

Via this identification, we can regard systems satisfying the Yang-Baxter equation as representations of this algebra $\TeL_n(-(q+q^{-1}))[u^{\pm}, v^{\pm}].$ We may obtain one such representation via the map 
\[\phi: \TeL_n(-(q+q^{-1})) \rightarrow \on{End}((\C^2)^{\otimes n})\]
sending
\[e_i \mapsto I \otimes I \otimes \ldots \otimes  I \otimes 
\begin{bmatrix}
	0 & 0 & 0 & 0\\
	0 & -q^{-1} & 1 & 0\\
	0 & 1 & -q & 0\\
	0 & 0 & 0 & 0
\end{bmatrix} \otimes I \otimes \ldots \otimes I,\]
where the matrix is located in the $i$ and $i+1$ coordinates. 

One can check that this map respects the Temperley-Lieb relations, and that it induces a representation $\rho: \TeL_n(-(q+q^{-1}))[u^{\pm}, v^{\pm}] \rightarrow \on{End}((\C^2)^{\otimes n})$ sending
\[\Rcheck_i(u) \mapsto I \otimes \ldots \otimes  I \otimes 
\begin{bmatrix}
	qu-q^{-1}u^{-1} & 0 & 0 & 0\\
	0 & u(q-q^{-1}) & u-u^{-1} & 0\\
	0 & u-u^{-1} & u^{-1}(q-q^{-1})& 0\\
	0 & 0 & 0 & qu-q^{-1}u^{-1}
\end{bmatrix} \otimes I \otimes \ldots \otimes I\]

\subsection{Loop Models}

\begin{Definition}[Loop Model]
	A \textbf{loop model} is an assignment of the tiles \tikzfig{LoopModelPiece1} and \tikzfig{LoopModelPiece2} to the $k \times n$ rectangle
	\ctikzfig{LoopModelRectangle}
\end{Definition}

We can compute the \textbf{fugacity} of a loop model with respect to a parameter $q \not = \pm 1$ by assigning a fugacity of $a(x_i/y_j)$ to the \tikzfig{LoopModelPiece1} tile, and $b(x_i/y_j)$ to the \tikzfig{LoopModelPiece2} tile, and multiplying by $\tau^{\#\text{ closed loops}}$, where $\tau = -(q+q^{-1})$. That is, the fugacity is
\[\tau^{\#\text{ closed loops}} \cdot \prod_{i=1}^{k}\prod_{j=1}^n
\begin{cases}
	a(x_i/y_j) & \tikzfig{LoopModelPiece1}\\
	b(x_i/y_j) & \tikzfig{LoopModelPiece2}
\end{cases}\]

When $q = \pm 1$, we instead assign weights of $a(x_i -y_j)$ and $b(x_i-y_j)$ respectively, so that the fugacity of the loop model is

\[\tau^{\#\text{ closed loops}} \cdot \prod_{i=1}^{k}\prod_{j=1}^n
\begin{cases}
	a(x_i - y_j) & \tikzfig{LoopModelPiece1}\\
	b(x_i - y_j) & \tikzfig{LoopModelPiece2}
\end{cases}\]

%Add a worked example of fugacity computation.

\subsection{Loop Models and Grassmannians}

Let $X = T^*\Gr(k, n)$ be the cotangent bundle of the Grassmannian. We wish to consider its $T \times \C^\times$-equivariant cohomology. Observe that
\[H_{T \times \C^\times}^*(X) \cong \Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k}/\cI,\]
where:

\begin{itemize}
	\item The ring $\Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k}$ consists of polynomials symmetric in the $x_i$, i.e., invariant under the action of $S_k$ on $x_1, \ldots, x_k$. \item $\cI$ is the ideal generated by polynomials which vanish when each $x_i$ is replaced by some (distinct) $y_j$. 
	%is this actually correct? I have in my notes that $\cI = \cap \ker \phi_I,$ but I'm not sure that agrees with the example PZJ gave for $k=1$.
	That is, for any $I \in \binom{[n]}{k}$, we can define a map 
	\[\phi_I: \Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k} \rightarrow \Z[y_1, \ldots y_n, h]\] 
	which sends $p(x_1, x_2, \ldots, x_k, y_1, \ldots, y_n, h)$ to $p(y_{I_1}, y_{I_2}, \ldots, y_{I_k}, y_1, \ldots, y_n, h).$ Note that the order on the elements of $I$ does not matter, since $p$ is symmetric in the $x_i.$ Then $\cI$ is the ideal generated by the kernels of the $\phi_I.$
\end{itemize}
For example, when $k=1$, we have that $\cI = \langle (x_1 - y_1), (x_1-y_2), \ldots, (x_1-y_n) \rangle,$ so that
\[H_{T \times \C^\times}^*(\Gr(1,n)) \cong \Z[x_1, y_1, \ldots, y_n, h]^{S_k}/\cI\]

Now, for each $I \in \binom{[n]}{k}$, let $X_I^\circ = B_{-}\C^I,$ where $\C^I$ is the coordinate subspace spanned by $e_{I_1}, \ldots, e_{I_k},$ denote the Schubert cell corresponding to $I$. One can check that $X_I^\circ  \cong \C^{k(n-k)-\on{inv}(I)},$ where $\on{inv}(I)$ is the inversion number of the binary string corresponding to $I$. In particular, $X_I^\circ$ is smooth.

Let $C_I = \overline{\C_{X_I^\circ} \Gr(k, n)}$ denote the closure of the conormal bundle of $X_I^\circ$ in $T^*(\Gr(k,n)).$ Let $\Stil_I = [C_I] \in H_{T \times \C^\times}^*(X)$ be the fundamental class of this conormal bundle.

Recall that when examining $H_T^*(\Gr(\cdot, n)),$ the $T$-equivariant cohomology of $\bigsqcup_{k=1}^n \Gr(k,n),$ we assigned 
\[S_I \mapsto \bigotimes_{i=1}^n \begin{cases}
	\begin{pmatrix}
		1 & 0
	\end{pmatrix}^{Tr} & i \not \in I\\
	\begin{pmatrix}
		0 & 1
	\end{pmatrix}^{Tr} & i \in I
\end{cases}\]

In the case of the cotangent bundle, we attach an element of $(\C^2)^{\otimes n}$ to each $\Stil_I$ via \textbf{link patterns}. We begin with the binary string associated to $I$, and repeatedly attach links between each substring of $1 0$, ignoring previously linked letters. This is perhaps most easily illustrated with an example: if our binary string is $01101001$, the associated link pattern would be \ctikzfig{LinkPattern}
To the link \tikzfig{LinkPatternij} between positions $i$ and $j$, we associate
$\begin{pmatrix}
	1\\
	0
\end{pmatrix}_i
\otimes
\begin{pmatrix}
	0\\
	1
\end{pmatrix}_j
-
q^{-1}
\begin{pmatrix}
	0\\
	1
\end{pmatrix}_i
\otimes
\begin{pmatrix}
	1\\
	0
\end{pmatrix}_j,
$
while to a ``lonely" $0$ or $1$ in position $i$ we associate $\begin{pmatrix} 1\\ 0\end{pmatrix}_i$ and $\begin{pmatrix} 0\\ 1\end{pmatrix}_i$ respectively. We then take the tensor product over the vectors associated to all links/lonely elements. 

\begin{Theorem}[Z-J, \href{https://doi.org/10.3842/SIGMA.2018.069}{Loop Models and $K$-Theory}, 2016]
	$\Stil_I = [C_I]$ is equal to the loop model partition function on a $k \times n$ rectangle where the connectivity of the external points satisfy:
	\begin{itemize}
		\item No bottom points are connected to other bottom points
		\item No top points are connected to right points
		\item The top lines reproduce the link pattern of the associated binary string.
	\end{itemize}
\end{Theorem}

\section{Lecture 15 (Allen Knutson)}

\begin{Definition}
	Let $0 = n_0 \leq n_1 \leq n_2 \leq \dots \leq n_d \leq n_{d+1} = n$ be a sequence of integers, we define the Grothendieck-Springer space as
	\begin{equation*}
		\begin{aligned}
			\GS \coloneqq \{
			 & (\overrightarrow{\varepsilon} \in \C^d, V^* := (0 = V^{n_0} \subseteq V^{n_1} \subseteq V^{n_2} \subseteq \dots \subseteq V^{n_d} \subseteq V^{n_{d+1}}  =\C^n), X \in \End(\C^n)): \\
			 & \dim V^{n_i} = n_i, (X - \varepsilon_i) \cdot V^{n_i} \subseteq V^{n_{i-1}} \}
		\end{aligned}
	\end{equation*}
\end{Definition}

We think of $V^*$ as a partial flag and $n_i$ as its dimensions.

It is clear from the conditions that there is an action of $\GL_n(\C)$ on $\GS$ that preserves $\overrightarrow{\varepsilon}$, acts by multiplication on the flag $V^*$, and by conjugation on $X$.

\begin{Example}
	If we fix $V^*$ to be a standard partial flag, then the conditions imply that $X$ is a block matrix:
	\begin{equation*}
		\newcommand*{\tempb}{\multicolumn{1}{|c}{}}
		\newcommand*{\tempc}{\multicolumn{1}{c|}{}}
		X = \left[\begin{array}{cccccccc}
				\varepsilon_1    &        & \text{\large{0}} & \tempb        &        &        &                  &        \\
				                 & \ddots &                  & \tempb        &        &        & \text{\LARGE{*}} &        \\
				\text{\large{0}} &        & \varepsilon_1    & \tempb        &        &        &                  &        \\ \cline{1-5}
				                 &        & \tempc           & \varepsilon_2 & 0      & \tempb &                  &        \\
				                 &        & \tempc           & 0             & \ddots & \tempb &                  &        \\ \cline{4-5}
				                 &        &                  &               &        & \ddots &                  &        \\ \cline{7-8}
				                 &        & \text{\LARGE{0}} &               &        & \tempc & \varepsilon_d    & 0      \\
				                 &        &                  &               &        & \tempc & 0                & \ddots \\
			\end{array}\right]
	\end{equation*}
\end{Example}

\begin{Example}
	If we fix $\overrightarrow{\varepsilon} = \overrightarrow{0}$ then we have the isomorphism
	\[
		\GS|_{\overrightarrow{\varepsilon}=0} \cong \text{T}^* \Fl(n_1, \dots, n_d; \C^n).
	\]
\end{Example}

\begin{Example}
	Let $\overrightarrow{\varepsilon}$ be non-repeating, $n_i=i$ and $d=n$. Then we have
	\[
		X \in \GL_n(\C) \cdot
		\begin{bmatrix*}
			\varepsilon_1&&\text{\large{0}}\\
			&\ddots&\\
			\text{\large{0}}&&\varepsilon_n
		\end{bmatrix*}.
	\]
	Hence, the full flag $V^*$ is determined from $X$ by taking appropriate sums of the (one dimensional) eigenspaces,
	and we obtain that the fiber is the homogeneous space
	\[
		\GS|_{\overrightarrow{\varepsilon}} \cong \GL_n / T.
	\]
\end{Example}

\begin{Remark}
	In general, $\GS$ is a manifold.
	For any fixed ${\overrightarrow{\varepsilon}}$, it is still a manifold since it's a bundle over the flag manifold and the fibers are smooth.
\end{Remark}

\begin{Remark}
	If we fix ${\overrightarrow{\varepsilon}} = {\overrightarrow{0}}$ and forget the flag, then the image of $\GS|_{\overrightarrow{\varepsilon}=0}$ in $\End(\C^n)$ is the cone of nilpotent matrices, which is singular. This is what Springer thought about, taking $\GS|_{\overrightarrow{\varepsilon}=0}$ as a resolution of singularities of the nilpotent cone.
\end{Remark}

\begin{Remark}
	Outside of Type $A$, we can consider $\GS$ as well.
	We take $V^* \in G/P$, $X \in \Lie(G)^\vee$, $\overrightarrow{\varepsilon} \in Z(\text{Levi}(P))$ and one can figure out the appropriate conditions make it work.
\end{Remark}

Recall the Bruhat decomposition
\[
	G/B = \bigsqcup_{w \in W} B_- w B / B
\]

and consider the similar inclusion

\[
	G/T \supseteq \bigsqcup_{w \in W} B_- w T/T
\]

The action of $W = N(T)/T$ on $G/T$ by right-multiplication permutes the spaces $B_- w T/T$ transitively.

Looking at the simplest $B_- T/T$, it is closed in $G/T$ since $B_-$ is closed in $G$. Hence, \textbf{all} the spaces $B_- w T/T$ are closed and have the same dimension $\dim (B_- T/T) = \frac{1}{2} \dim (G/T)$.

In particular, this implies that the inclusion is strict unless $G$ is trivial.

\begin{Remark}
	This is very different from the Bruhat decomposition of $G/B$!
\end{Remark}

We wish to take the "limit" ${\overrightarrow{\varepsilon}} \to {\overrightarrow{0}}$ to get from $G/T$ to $\text{T}^* G/B$. Similarly, on the right, we wish to consider the "limit" of the graph of an action $r_\alpha \in W$. This should give us an auto-correspondence at $\overrightarrow{\varepsilon} = \overrightarrow{0}$.

Fix a reflection $r_\alpha \in W$ and consider its action on $\GS|_{\overrightarrow{\varepsilon}}$, we denote its graph by
\[
	\text{graph}(r_\alpha) \subseteq
	(\GS|_{\overrightarrow{\varepsilon}})^2 \subseteq \GS^2.
\]

By varying over \textbf{generic} (non-repeating) $\overrightarrow{\varepsilon}$ we can consider the set
\[
	\overline{
		\bigcup_{\overrightarrow{\varepsilon}\text{non-repeating}} \text{graph}(r_\alpha)
	}
	\subseteq \GS^2
\]

This closure is going to tell us what happens at $\overrightarrow{0}$, where we can extract the desired auto-correspondence $\subseteq \GS|_{\overrightarrow{\varepsilon}=0} \times \GS|_{\overrightarrow{\varepsilon}=0}$.

\begin{Example}
	To see this construction in action, we can consider $\C^\times$ acting by division on $\C$. Then, the graph of $t \in \C^\times$ is $\text{graph}(t) = \{ (x,y) : y = x/t\}$, so the corresponding set is
	\[
		\overline{
			\bigcup_{t\in \C^\times} \text{graph}(t)
		} =
		\overline{
			\{ (x,y,t) : y=x/t\}
		} = \{ (x,y,t) : t y=x\}.
	\]
	From this we get the limit of $t \to 0$ as $\{(x,y): x=0\}$.
\end{Example}

Recall that in our case, $\GS|_{\overrightarrow{\varepsilon}=0} = \text{T}^* \GL_n/B$, so by the limit correspondence, we obtain an action
\[
	H^*_{T \times \C^\times}(\text{T}^* \GL_n/B) \circlearrowleft r_i.
\]

Recall that
\[
	H^*_{T \times \C^\times}(\text{T}^* \GL_n/B) = \Z[x_1, \dots, x_n, y_1, \dots, y_n, \hbar] / \la p(x) = p(y) \text{ for } p \text{ symmetric} \ra
\]
so that the action of $r_i$ is algebraically given by the operator $r_i^x + \hbar \partial_i^x$ where $r_i^x$ swaps $x_i$ with $x_{i+1}$, and  $\partial_i^x = \frac{1}{x_i-x_{i+1}} (1-r_i^x)$. Note that $r_i$ is indeed an action since $r_i^2 = 1$.

In the following, we are interested in computing the classes of the limits of $B_- w T/T$ in $H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$. In fact, we need only consider one such class, since we know that the action of $W$ is transitive.

We start with the base case $w_0^{(n)}$ and consider the polynomial
\[
	\MO_{w_0^{(n)}} = S_{w_0^{(n)}} = \prod_{i+j\leq n} (x_i-y_j),
\] where $\MO$ stands for Maulik Okounkov, to obtain the general case
\[
	\MO_w = \left(\prod_{\text{reduced word for } w^{-1}w_0^{(n)}} (r_i + \hbar \partial_i)\right) \MO_{w_0^{(n)}}.
\]

As we did with double Schubert polynomials, we define the restriction to a point $v \in W$ by
\[
	\cdot\  |_v \coloneqq (x_i \mapsto y_{v(i)})
\]
so that $\MO_w |_v \in H_{T \times \C^\times}^*(\text{pt}) = \Z[y_1, \dots, y_n, \hbar]$.

In the following, we would like to see if the classes of the limits are a basis for $H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$.

\begin{Definition}
	Denote the limit of the space $B_-w T/T$ by
	\[
		(\MO \text{ "stable Lagrangian cycle"})_w \coloneqq \lim_{\varepsilon\to 0} B_-w T/T \subseteq \text{T}^* \GL_n/B.
	\]
\end{Definition}

Then, by restricting to every point of $W$ and comparing classes, we can conclude that

\begin{Theorem}
	\[
		[ (\MO \text{ "stable Lagrangian cycle"})_w ]  \mapsfrom \MO_w \in \mathbb{Z}[x_1,\dots,x_n, y_1, \dots, y_n, \hbar]
	\]
	where $[ (\MO \text{"stable Lagrangian cycle"})_w ] \in H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$.
\end{Theorem}

\begin{Definition}
	The opposite $\MO$ class of $w$ is given by
	\[
		(\MO^w =\ )\  \widetilde{\MO_w} \coloneqq w_0^{(n)} \cdot \MO_w
	\]
	where $w_0^{(n)}$ acts by $y_i \mapsto y_{n+1-i}$.
\end{Definition}

The classes $\MO_w$ and $\MO^w$ are dual in the sense that they are both classes of Lagrangian spaces in $\text{T}^* \GL_n/B$ which we can intersect and integrate in equivariant cohomology to get the expected duality (ignoring the non-compactness of $\text{T}^* \GL_n/B$, via fixed points).

Finally, comparing with the Schubert basis, the $\MO$ classes are a basis in the following sense:
\begin{Proposition}
	The classes $[\MO_w]$ are a basis over $\text{frac}(H^*_{T\times\C^*})$.
\end{Proposition}

\section{Lecture 16 (Allen Knutson)}

\section{Lecture 17 (Paul Zinn-Justin)}

\section{Lecture 18 (Paul Zinn-Justin)}

\end{document}
