\documentclass[12pt]{amsart}

\usepackage{tikz}
\usepackage{bbm}
\usetikzlibrary{3d,arrows,calc,positioning,decorations.pathreplacing,matrix} %,arrows.meta}

\usepackage{calligra,mathrsfs}
\usepackage[all]{xy}
\usepackage{float, comment}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsbsy}
\usepackage{amstext}
\usepackage{amsopn}
\usepackage{stmaryrd}
%\usepackage{mathrsfs} % allows \mathscr
\usepackage[mathscr]{eucal}
\usepackage{enumerate}
\usepackage{xcolor}
\usepackage{graphicx} % allows \includegraphics{}s
\usepackage{tikz-cd}
\usepackage{scalerel}
\usepackage{microtype} % improves formattings
\usepackage[margin=1in,marginparwidth=0.8in, marginparsep=0.1in]{geometry}
\renewcommand{\baselinestretch}{1.2} % changes page formatting
\usepackage[pagebackref, bookmarks=true, bookmarksopen=true, bookmarksdepth=3,bookmarksopenlevel=2, colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, menucolor=blue, urlcolor=blue]{hyperref}
% \usepackage{newtxtext} % improves font appearance
\usepackage{tikz}
\usepackage{bbm}
\usepackage[all]{xy}
\usetikzlibrary{arrows,calc,positioning,decorations.pathreplacing,braids,cd} %,arrows.meta}

%Path relative to the main .tex file 
\graphicspath{ {./figures/} }

\newcommand{\blue}{\color{blue}}
\newcommand{\red}{\color{red}}

\usepackage{tikz-cd}
\hypersetup{
    colorlinks=true,
    citecolor=red,
    linkcolor=blue,
    urlcolor=red,
}
\usepackage[capitalize, nameinlink]{cleveref}

\numberwithin{equation}{section}
\newtheorem{Theorem}[equation]{Theorem}
\newtheorem{Proof}[equation]{Proof}
\newtheorem{Proposition}[equation]{Proposition} 
\newtheorem{Lemma}[equation]{Lemma}
\newtheorem{Open}[equation]{Open Question}
\newtheorem{Corollary}[equation]{Corollary}
\newtheorem{Conjecture}[equation]{Conjecture}
\newtheorem{Specialthm}{Theorem}
\newtheorem{Question}{Question}

\theoremstyle{definition}
\newtheorem{Remark}[equation]{Remark}
\newtheorem{Example}[equation]{Example}
\newtheorem{Definition}[equation]{Definition}

\numberwithin{figure}{section}

\def\la{\langle}
\def\ra{\rangle}
\def\ttimes{\widetilde{\times}}
\def\tbox{\widetilde{\boxtimes}}
\def\bbox{{\boxtimes}}
\def\O{\mathcal{O}}
\def\K{\mathcal{K}}
\def\bG{\mathbb{G}}
\newcommand{\gr}{\mathrm{gr}}
\newcommand{\wt}{\text{wt}}
\newcommand{\mb}[1]{\mathbf{#1}}
\newcommand{\fsl}{\mathfrak{sl}}
\newcommand{\fg}{\mathfrak{g}}
\newcommand{\fn}{\mathfrak{n}}
\newcommand{\bk}{{\mathbbm k}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\D}{\mathbb{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\bN}{\mathbb{N}}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\bfC}{{\mathbf{C}}}
\newcommand{\bfD}{{\mathbf{D}}}
\newcommand{\bfI}{{\mathbf{I}}}
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\sW}{\mathscr{W}}
\newcommand{\sX}{\mathscr{X}}
\newcommand{\sY}{\mathscr{Y}}
\newcommand{\sZ}{\mathscr{Z}}

\newcommand{\hs}{\heartsuit}
\newcommand{\bul}{\bullet}
\newcommand{\ga}{\gamma}
\newcommand{\al}{\alpha}
\newcommand{\be}{\beta}

%Commands for Lecture 12
\newcommand{\GL}{\operatorname{GL}}
\newcommand{\Sym}{\operatorname{Sym}}
\newcommand{\pt}{\operatorname{pt}}
\newcommand{\codim}{\operatorname{codim}}
\newcommand{\End}{\operatorname{End}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\spn}{\operatorname{span}}

%Commands for Lecture 14
\newcommand{\on}[1]{\operatorname{#1}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\Gr}{\on{Gr}}
\newcommand{\TeL}{\on{TL}}
\newcommand{\Rcheck}{\breve{R}}
\newcommand{\Stil}{\tilde{S}}
\usepackage{tikzit}
\input{tikzit_styles.tikzstyles}

%Commands for Lecture 13, 15
\newcommand{\GS}{\operatorname{GS}}
% \newcommand{\GL}{\mathrm{GL}}
\newcommand{\Fl}{\operatorname{\mathscr{F}\!\ell}}
% \newcommand{\End}{\mathrm{End}}
\newcommand{\Lie}{\operatorname{Lie}}
\newcommand{\MO}{\operatorname{MO}}


%% code from mathabx.sty and mathabx.dcl
\DeclareFontFamily{U}{mathx}{\hyphenchar\font45}
\DeclareFontShape{U}{mathx}{m}{n}{
	<5> <6> <7> <8> <9> <10>
	<10.95> <12> <14.4> <17.28> <20.74> <24.88>
	mathx10
}{}
\DeclareSymbolFont{mathx}{U}{mathx}{m}{n}
\DeclareFontSubstitution{U}{mathx}{m}{n}
\DeclareMathAccent{\widecheck}{0}{mathx}{"71}
\DeclareMathSymbol{\shortminus}{\mathbin}{AMSa}{"39}

\DeclareRobustCommand{\SkipTocEntry}[5]{}

\newcommand{\arrtip}{latex'}

%Custom commands

\newcommand{\grass}[2]{\mathrm{Gr}(#1,#2)}
\newcommand{\fl}{\mathcal{FL}}
\newcommand{\gl}{\mathrm{GL}}
\newcommand{\attr}{\mathrm{attr}}
\newcommand{\attrl}{\mathrm{attrlang}}
\newcommand{\set}[1]{\left\{ #1 \right\}}
\newcommand{\paren}[1]{\left( #1 \right)}

\newenvironment{ccd}{\begin{center}
\begin{tikzcd}}{\end{tikzcd}
\end{center}}

\tikzset{gauged/.style={rectangle,rounded corners=2mm,draw,inner sep=1mm,minimum size=4mm}}
\tikzset{framed/.style={rectangle,draw,inner sep=0.5mm,minimum size=4mm}}
\tikzset{script math mode/.style = {execute at begin node=$ , execute at end node=$}}
\newcommand\dOne[2]{
\node[gauged] at (1,0) (v1) {#1}; 
\node[gauged] at (2,0) (v2) {#2}; 
\draw (v1) -- (v2);
}

\begin{document}
\title{Notes on Schubert Calculus and Quantum Integrability}

\begin{abstract}
\end{abstract}

\maketitle

\setcounter{tocdepth}{1}

\tableofcontents

\section{Introduction}

\thispagestyle{empty}

Here is a template for a simple commutative diagram in tikz:
\begin{equation*}
\begin{tikzpicture}
[baseline=(current  bounding  box.center),thick,>=\arrtip]
\node (a) at (0,0) {$X'$};
\node (b) at (2.5,0) {$Y'$};
\node (c) at (0,-1.5) {$X$};
\node (d) at (2.5,-1.5) {$Y$};
\draw[->] (a) to node[above] {$f' $} (b);
\draw[->] (b) to node[right] {$h $} (d);
\draw[->] (a) to node[left] {$h' $}(c);
\draw[->] (c) to node[above] {$f $} (d);
\end{tikzpicture}
\end{equation*}

Here is a template for an elaborate commutative diagram in tikz:
\begin{equation*}
\begin{tikzpicture}[baseline=(current  bounding  box.center),thick,>=\arrtip]
\newcommand*{\ha}{1.6}; \newcommand*{\hb}{1.6}; \newcommand*{\hc}{1.6};
\newcommand*{\va}{-1.1}; \newcommand*{\vb}{-1.1}; \newcommand*{\vc}{-1.1};
\node (ab) at (\ha,0) {$X_\al'$};
\node (ad) at (\ha+\hb+\hc,0) {$Y_\al'$};
\node (ba) at (0,\va) {$X'$};
\node (bc) at (\ha+\hb,\va) {$Y'$};
\node (cb) at (\ha,\va+\vb) {$X_\al$};
\node (cd) at (\ha+\hb+\hc,\va+\vb) {$Y_\al$};
\node (da) at (0,\va+\vb+\vc) {$X$};
\node (dc) at (\ha+\hb,\va+\vb+\vc) {$Y$};
\draw[->] (ab) to node[above] {$\phi' $} (ad);
\draw[->] (ab) to node[above] {$ $} (ba);
\draw[->] (ab) to node[left,pos=.8] {$\psi' $} (cb);
\draw[->] (ad) to node[above] {$ $} (bc);
\draw[->] (ad) to node[right] {$\psi $} (cd);
\draw[->] (ba) to node[above] {$ $} (da);
\draw[->] (cb) to node[above,pos=.2] {$\phi $} (cd);
\draw[->] (cb) to node[above] {$ $} (da);
\draw[->] (cd) to node[above] {$ $} (dc);
\draw[->] (da) to node[above,pos=.6] {$f $} (dc);
\draw[-,line width=6pt,draw=white] (ba) to  (bc);
\draw[->] (ba) to node[above,pos=.75] {$f' $} (bc);
\draw[-,line width=6pt,draw=white] (bc) to  (dc);
\draw[->] (bc) to node[right,pos=.2] {$h $} (dc);
\end{tikzpicture}
\end{equation*}


\section{Lecture 1 (Allen Knutson)}

Let $V$ be a $k$-plane in $\C^n$ with basis represented as a $k\times n$ matrix with basis elements as row vectors. Put this matrix into Reduced Row Echelon Form and consider left action by $GL_k(\C)$ and right action by upper triangular matrices to get an open subgroup of \textit{right word row operations}.

\begin{Theorem}
	A matrix $\text{Mat}_n(\C)$ acted on the left by $GL_k(\C)$ downward row operations and  on the right by upper triangular matrices rightward column operations, that is,
	$$\begin{tikzpicture}
		\node (a) at (.3,.3) {$*$};
		\node (b) at (.7,.7) {$0$};
		\draw [-] (.9,.1) to (.1,.9);
		\draw[-] (0,0) to (0,1);
		\draw[-] (1,0) to (1,1);
		\draw[-] (0,0) to (.1,0);
		\draw[-] (0,1) to (.1,1);
		\draw[-] (.9,0) to (1,0);
		\draw[-] (.9,1) to (1,1);
		\node (c) at (2.5,.5) {$\circlearrowright$Mat$_n(\C)\circlearrowleft$};
		\node (a) at (4.3,.3) {$0$};
		\node (b) at (4.7,.7) {$*$};
		\draw [-] (4.9,.1) to (4.1,.9);
		\draw[-] (4,0) to (4,1);
		\draw[-] (5,0) to (5,1);
		\draw[-] (4,0) to (4.1,0);
		\draw[-] (4,1) to (4.1,1);
		\draw[-] (4.9,0) to (5,0);
		\draw[-] (4.9,1) to (5,1);
	\end{tikzpicture}$$
	has one orbit for each partial permutation matrix. This is the \textbf{Bruhet decomposition} of the matrix.
\end{Theorem}

\begin{Definition}
	A matrix \textbf{Schubert Variety} is $\overline{X_{\pi}}:=\overline{B_-\pi B_+}$ where $\pi$ is the permutation matrix.
\end{Definition}

\begin{Theorem}
	$\overline{X_\pi}$ is the set of $n\times n$ matrices, $M$, such that for all $i,j\in[n]$, the $i\times j$ submatrix of $M$ is less than or equal to the $i\times j$ submatrix of $\pi$. That is, the determinants summarized by these conditions generate a prime ideal whose vanishing set is $\overline{X_\pi}$.
\end{Theorem}

As an example, consider $\pi=3142$ pictured below:

\begin{center}
	\begin{tikzpicture}
		\node (40) at (0,.5) {$2$};
		\node (30) at (0,1.5) {$4$};
		\node (20) at (0,2.5) {$1$};
		\node (10) at (0,3.5) {$3$};
		\node (21) at (1,2.5) {$1$};
		\node (11) at (1,3.5) {$0$};
		\node (42) at (2, .5) {$1$};
		\node (32) at (2,1.5) {$*$};
		\node (12) at (2,3.5) {$0$};
		\node (13) at (3,3.5) {$1$};
		\node (34) at (4,1.5) {$1$};
		\draw[-] (.5,0) to (.5,4);
		\draw[-] (4.5,0) to (4.5,4);
		\draw[-] (.5,0) to (4.5,0);
		\draw[-] (.5,4) to (4.5,4);
		\draw[->] (2.5,.5) to (4.3,.5);
		\draw[->] (1,2) to (1,.5);
		\draw[->] (1.5,2.5) to (4,2.5);
		\draw[->] (4,1) to (4,.3);
		\draw[->] (3,3) to (3,.3);
		\draw[->] (3.5,3.5) to (4.3,3.5);
	\end{tikzpicture}
\end{center}
The arrows are referred to as \textbf{death rays} since each leading one eliminates the entries to the right of and below it. In this example we have that $$m_{11}=m_{12}=0=\det\left ( \begin{array}{cc} m_{21} & m_{22} \\ m_{31} & m_{32}  \end{array}\right )$$ and the associated \textbf{Rothe diagram} is $$\left [ \begin{array}{cc} 0 & 0 \\ & *\end{array}\right ]$$

Two natural questions arise. First, how big is $\overline{X_\pi}$? We see that \begin{align*}
	\dim\overline{X_\pi}&=\dim(B_-\pi B_+) \\
	&= \dim(B_-\times B_+)-\dim(\text{stab}(\pi))\\
	&=\text{the number of entries crossed out in the death ray diagram}\\
	&=\dim T_\pi(B_-\pi B_+)\\
	&=\dim(b_-\pi+\pi b_+)
\end{align*}
Where $b_-$ and $b_+$ are lie algebras. Hence the codimension of $\overline{X_\pi}$ is the number of entries in the Rothe diagram.

\begin{Theorem}
	The only essential rank conditions are at the southeast corners of the Rothe diagram.
\end{Theorem}

The second question is what is the volumn of $\P(\overline{X_\pi})$?
Considering the degree as a projective variety, we get the following axioms for $Y\subseteq\P(V)$ defined by some homogeneous ideal.
\begin{enumerate}
	\item[(0)] The degree of $p^1$ is 1.
	\item If $Y$ is reducible, that is the ideal is not prime, such that $Y=Y_1\cup Y_2\cup\cdots\cup Y_k$ and $I\subseteq P_i$ is minimal, then the degree of $Y$ is the sum over the top dimensional components of the product of the multiplicity of $Y_i$ and the degree of $Y_i$.
	\item If $W\subseteq V$ is a hyperplane and $\P(W)\supseteq Y$ then the degree of $Y$ in $\P(V)$ is equal to the degree of $Y$ in $\P(W)$.
	\item If $W\subseteq V$ is a hyperplane and Y is reduced and irreducible, that is I is prime and $Y\subseteq \P(W)$, then the degree of $Y$ in $\P(V)$ is equal to the degree of $Y\cap\P(W)$ in $\P(W)$.
	
\end{enumerate}

What is the degree of $\P(\overline{X_\pi})$? Consider the base case where $$\pi=w_0^{(n)}=
\vcenter{\hbox{\begin{tikzpicture}
			\node at (.2,.2) {1};
			\node at (.8,.8) {1};
			\node at (.4,.4) {$\cdot$};
			\node at (.5,.5) {$\cdot$};
			\node at (.6,.6) {$\cdot$};
			\draw[-] (0,0) to (0,1);
			\draw[-] (0,0) to (.2,0);
			\draw[-] (0,1) to (.2,1);
			\draw[-] (1,0) to (1,1);
			\draw[-] (.8,0) to (1,0);
			\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}$$.

After eliminating entries via death rays we see that
$\overline{X_\pi}=\left \{ M: \vcenter{\hbox{\begin{tikzpicture}
			\node at (.2,.8) {0};
			\node at (.8,.2) {*};
			\draw[-] (.2,.2) to (.8,.8);
			\draw[-] (0,0) to (0,1);
			\draw[-] (0,0) to (.2,0);
			\draw[-] (0,1) to (.2,1);
			\draw[-] (1,0) to (1,1);
			\draw[-] (.8,0) to (1,0);
			\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}\right \}$
where the $0$'s in the upper left of the matrix aligns with axiom 2 and the free variables in the lower left align with axiom 3. This gives us that $\deg(\overline{X_\pi})=1$.

If $\pi\neq w_0^{(n)}$ pick $i\in[n]$ least such that $\pi(i)\neq w_0^{(n)}(i)=n+1-i$. Then $W:=\{ M: m_i\pi(i)=0\}$ and $$\overline{X_\pi}\cap W=\overline{X_\pi}\cap\left\{ \vcenter{\hbox{\begin{tikzpicture}
			\node at (0,0) {$i$};
			\node at (1,1.1) {$\pi(i)$};
			\node at (.6,.4) {$0$};
			\draw[-] (.2,.8) to (.2,-.8);
			\draw[-] (.2,-.8) to (1.8,-.8);
			\draw[-] (1.8,-.8) to (1.8,.8);
			\draw[-] (1.8,.8)to (.2,.8);
			\draw[-] (1,0) to (1,.8);
			\draw[-] (.2,0) to (1,0);
\end{tikzpicture}}}\right\}\circlearrowleft B_-\times B_+ \text{ invariant}$$ which is the union of $\overline{X_{\pi'}}$ over certain $\pi'$ none of which are strictly partial permutations and all multiplicities are $1$.

\begin{Definition}
	A \textbf{pipe dream} for $\pi$ is a diagram $$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (5,4);
				\draw[-] (5,4) to (5,0);
				\draw[-] (5,0) to (1,0);
				\draw[-] (1,0) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (...) at (3.5,4.5) {$\cdots$};
				\node (n) at (4.5,4.5) {$n$};
				\node (p1) at (0,3.5) {$\pi(1)$};
				\node (p2) at (0,2.5) {$\pi(2)$};
				\node (p) at (0,1.5) {$\hdots$};
				\node (pn) at (0,.5) {$\pi(n)$};
				\draw[-] (2,4) to (2,0);
				\draw[-] (3,4) to (3,0);
				\draw[-] (4,4) to (4,0);
				\draw[-] (1,1) to (5,1);
				\draw[-] (1,2) to (5,2);
				\draw[-] (1,3) to (5,3);
				\draw[-] (1,4) to (5,4);
	\end{tikzpicture}}}$$
	where each box is filed in with one of two tiles: crosses $\vcenter{\hbox{\begin{tikzpicture}
				\node at (0,.5) {j};
				\node at (.5,1) {i};
				\node at (1,.5) {j};
				\node at (.5,0) {i};
				\draw[-] (.2,.2) to (.2,.8);
				\draw[-] (.2,.8) to (.8,.8);
				\draw[-] (.8,.8) to (.8,.2);
				\draw[-] (.8,.2) to (.2,.2);
				\draw[-] (.2,.5) to (.8,.5);
				\draw[-] (.5,.2) to (.5,.8);
	\end{tikzpicture}}}$ when $i\leq j$ and elbows $\vcenter{\hbox{\begin{tikzpicture}
				\node at (0,.5) {i};
				\node at (.5,1) {i};
				\node at (1,.5) {j};
				\node at (.5,0) {j};
				\draw[-] (.2,.2) to (.2,.8);
				\draw[-] (.2,.8) to (.8,.8);
				\draw[-] (.8,.8) to (.8,.2);
				\draw[-] (.8,.2) to (.2,.2);
				\draw (.2,.5) arc[start angle=-90, end angle=0, radius=.3];
				\draw (.5,.25) arc[start angle=180, end angle=90, radius=.3];
	\end{tikzpicture}}}$ when $i\neq j$.
\end{Definition}

\begin{Theorem}
	The degree of $\overline{X_\pi}$ is the number of pipe dreams of $\pi$.
\end{Theorem}
For a torus $T\cong (\C^x)^N$ and $Y\subseteq V)\circlearrowleft T$ where $Y$ is a $T$-invariant subvariety and $V$ is a $T$-representation can soup up the degree to a $T$-equivariant cohomology class. 

Our above axioms hold from above with the exception of axiom 2 which can be rewritten at follows: \begin{enumerate}
	\item[(2)] $[Y\subseteq V]$ equals the weight of $T(V/W)[Y\subseteq W]$ for $T\in T^*$. The $T^*$ weight lattice is given by Hom$(T,\C^x)\cong\Z^N$ such that for $\Lambda=(\lambda_1,\ldots,\lambda_N)\in\Z^N$ and $t=(t_1,\ldots,t_N)\in(\C^x)^N$, $\Lambda\cdot t=\prod\limits_{i=1}^N t_i^{\lambda_i}$. Then $[Y\subseteq V]\in\text{Sum}(T^*)\cong\Z[Y_1,\ldots,Y_n]$.
\end{enumerate}

\begin{Definition}
	The \textbf{Double Schubert Polynomial} is $S_\pi(X,Y)=[\overline{X_\pi}\subseteq\text{Mat}_n]$ with respect to $T\times T\circlearrowright\text{Mat}_n$ such that $\overline{S_\pi}(X,Y)=\sum\limits_{\text{p}}\prod\limits_{\text{c}}(X_{\text{row}}-Y_{\text{col}})$ where $p$ stands for pipe dreams for $\pi$ and $c$ represents crosses. 
\end{Definition}
Consider the possible pipe dreams for $\pi=132$.
\begin{center}
	$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (4,4);
				\draw[-] (4,4) to (4,1);
				\draw[-] (4,1) to (1,1);
				\draw[-] (1,1) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (3) at (3.5,4.5) {$3$};
				\node (p1) at (0,3.5) {$1$};
				\node (p2) at (0,2.5) {$3$};
				\node (p3) at (0,1.5) {$2$};
				\draw[-] (2,4) to (2,1);
				\draw[-] (3,4) to (3,1);
				\draw[-] (4,4) to (4,1);
				\draw[-] (1,1) to (4,1);
				\draw[-] (1,2) to (4,2);
				\draw[-] (1,3) to (4,3);
				\draw[-] (1,4) to (4,4);
				\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
				\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
				\draw (2,3.5) arc[start angle=-90, end angle=0, radius=.5]; %12
				\draw (2.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
				\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw[-] (1,2.5) to (2,2.5); %21
				\draw[-] (1.5,3) to (1.5,2);
				\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
				\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
				\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
				\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
				\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
				\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
	\end{tikzpicture}}}$
	\hspace{10mm} and \hspace{10mm}
	$\vcenter{\hbox{\begin{tikzpicture}
				\draw[-] (1,4) to (4,4);
				\draw[-] (4,4) to (4,1);
				\draw[-] (4,1) to (1,1);
				\draw[-] (1,1) to (1,4);
				\node (1) at (1.5,4.5) {$1$};
				\node (2) at (2.5,4.5) {$2$};
				\node (3) at (3.5,4.5) {$3$};
				\node (p1) at (0,3.5) {$1$};
				\node (p2) at (0,2.5) {$3$};
				\node (p3) at (0,1.5) {$2$};
				\draw[-] (2,4) to (2,1);
				\draw[-] (3,4) to (3,1);
				\draw[-] (4,4) to (4,1);
				\draw[-] (1,1) to (4,1);
				\draw[-] (1,2) to (4,2);
				\draw[-] (1,3) to (4,3);
				\draw[-] (1,4) to (4,4);
				\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
				\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
				\draw[-] (2.5,4) to (2.5,3); %12
				\draw[-] (2,3.5) to (3,3.5);
				\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
				\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,2.5) arc[start angle=-90, end angle=0, radius=.5]; %21
				\draw (1.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
				\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
				\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
				\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
				\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
				\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
				\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
				\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
	\end{tikzpicture}}}$
\end{center}
\vspace{5mm}
Frome these pipe dreams we see that the Double Schubert Polynomial is $S_{132}=(X_2-Y_1)+(X_1-Y_2)$.

\section{Lecture 2 (Allen Knutson)}

\section{Lecture 3 (Paul Zinn-Justin)}

\section{Lecture 4 (Paul Zinn-Justin)}

\section{Lecture 5 (Allen Knutson)}

% 6/7/22, Allen Knutson (Lecture 5 of 18 total)
% LaTeXed by Claire Mirocha claire_mirocha@berkeley.edu

Recall that matrix Schubert varieties are of the following form (where $\pi$ is a permutation matrix): $$\overline{X}_{\pi} \coloneqq \overline{\vcenter{\hbox{\begin{tikzpicture}
\node at (.2,.2) {*};
\node at (.8,.8) {0};
\draw[-] (.2,.8) to (.8,.2);
\draw[-] (0,0) to (0,1);
\draw[-] (0,0) to (.2,0);
\draw[-] (0,1) to (.2,1);
\draw[-] (1,0) to (1,1);
\draw[-] (.8,0) to (1,0);
\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}} \pi 
\vcenter{\hbox{\begin{tikzpicture}
\node at (.2,.2) {0};
\node at (.8,.8) {*};
\draw[-] (.2,.8) to (.8,.2);
\draw[-] (0,0) to (0,1);
\draw[-] (0,0) to (.2,0);
\draw[-] (0,1) to (.2,1);
\draw[-] (1,0) to (1,1);
\draw[-] (.8,0) to (1,0);
\draw [-] (.8,1) to (1,1);
\end{tikzpicture}}}} = \overline{B_- \pi B_+} \subset \text{Mat}_n$$

For a linear representation $V$, the action $T \curvearrowright (V \supset X)$ gives us $[X \subset V] \in \text{Sym}T^{\ast} \simeq \Z[y_1, \dots, y_d]$.

Importantly, note that we can \textit{always} split $V$ as a direct sum of irreducible $T$-representations: \\
$$V \cong \bigoplus_{\text{weights }\lambda} \C_{\lambda}^{\oplus m_{\lambda}} \; \text{ for some multiplicities } m_{\lambda} \in \bN$$


Recall also our pipe dream formula, from yesterday's definition of the double Schubert polynomial $S_{\pi}$:
$$S_{\pi}(x_1, \dots, x_n, y_1, \dots, y_n) = [\overline{X_{\pi}} \subset \text{Mat}_n] = \sum_{\text{(pipe dreams for } \pi)} \prod_{\text{(crosses)}}x_{\text{row}} - y_{\text{col}}$$

\vspace{1em}

\begin{Definition}[Multigraded Hilbert series]
For a vector space $V$ of dimension $n$ (not necessarily equal to $\dim T)$, define $R \coloneqq \text{Fun}(V) \cong \C[z_1, \dots, z_n]$. Then the multigraded Hilbert series of $R$ is the formal sum
$$ h_R \coloneqq \sum_{\text{weights } \lambda \text{ of } T} \dim_{\C}(R_{\lambda})\, e^{\lambda}  \quad \in \mathbb{Z}[e^{\pm y_1}, \dots, e^{\pm y_d}]$$
where $R_{\lambda}$ is the $\lambda$-weight space of $R$.
\end{Definition}

Note that we have $h_{\oplus R_i} = \oplus h_{R_i}$.

To ensure the dimensions of the above weight spaces are finite, we impose the ``attractive condition" (we'll call it this, because we like it) that all $\lambda_i$ must lie in an open half-space.

\begin{Example}
We have the weight $\text{wt}(z_1^2 z_3) = -2 \lambda_1 - 1 \lambda_3$ (note that the coefficients are negative because we are acting on the dual space).
\end{Example}

\begin{Example}
For $n=1$, we have $\C[z_1] = \text{Fun}(V)$. So $h_R = \sum_{k=0}^{\infty} e^{-k \lambda_1} = \frac{1}{1-e^{-\lambda_1}}$.
\end{Example}

\begin{Example}
For general $n$, using the calculation directly above, we obtain $\C[z_1, \dots, z_n] \cong \C[z_1] \otimes \dots \otimes \C[z_n]$. So $h_R = \Pi_{i=1}^{n}  \frac{1}{1-e^{-\lambda_i}}$.
\end{Example}

\begin{Definition}[Multigraded / $T$-equivariant module]
If $R \curvearrowright M$, we say that $M$ is a multigraded (i.e. $T$-equivariant) module if:
\begin{itemize}
    \item $T \curvearrowright M$ (i.e. $M = \oplus_{\lambda \in T^{\ast}} M_{\lambda}$)
    \item $r \in R_{\lambda}, m \in M_{\mu} \implies rm \in M_{\lambda + \mu}$
\end{itemize} \end{Definition}

\begin{Definition}[Multigraded Hilbert series of an $R$-module $M$]
For $M$ a finitely generated $R$-module, we define 
$$ h_M \coloneqq \sum_{\text{weights } \lambda \text{ of } T} \dim(M_{\lambda}) \, e^{\lambda} $$
\end{Definition} 

Note from the definition above that the multigraded Hilbert series is so named because it is not graded by $\mathbb{Z}$ or $\mathbb{N}$, but by the weight lattice for $T$. Being multigraded is the same as having a torus action.

\begin{Example}
If $M = Rm$ (a free $R$-module with one generator), and $\text{wt}(m) = \lambda_m$, then $h_M = e^{\lambda_m} h_R$.
\end{Example}

A key example is the case $M = R/I$,  where $I$ is a $T$-invariant ideal, and $X = V(I)$. This motivates the next definition: notice that if $I=0$ (so $X$ is the entire space $V$), then we'd like $[V \subset V]$ to be 1. Directly above, though, we've already computed this to be a sum not equal to 1. The ``$K$-theoretical version" here will fix this issue.

\begin{Definition}
Letting $X = V(I)$, we have $[X \subset V]_K \coloneqq \frac{h_{R/I}}{h_R}$.
\end{Definition}

\begin{Theorem}
$[X \subset V]_K$ is a Laurent polynomial in $\{e^{\lambda}\}$.
\end{Theorem}
\begin{proof}
Sketch: If $R/I$ is a finitely generated module over a Noetherian ring $R$, and $I = (f_1, \dots, f_n)$, then there is a finite free resolution of $R/I$:
$$ 0 \to \dots \to \oplus_i R[\mu_i] \to R \to R/I \to 0 $$
So, this free resolution terminates, and the Hilbert series we want is an alternating sum of Hilbert series corresponding to the terms in the free resolution. Using that the series ``commutes with direct sum," and the fact that we've already computed series for single terms, we obtain a finite Laurent polynomial.
\end{proof}

\begin{Example}
If $X \subset V$ is a linear subspace, with $V = X \oplus X'$, then $[X \subset V]_K = \prod_{\mu \in X'}(1-e^{-\mu}) \in \Z[e^{\pm \mu}]$, whereas $[X \subset V] = \prod_{\mu \in X'} \mu \in \text{Sym}T^{\ast} = \Z[y_1, \dots, y_n]$.
\end{Example}

\noindent Next, let's check which axioms for $[X \subset V]$ are still satisfied by $[X \subset V]_K$:
\begin{enumerate}
    \item[\checkmark (0)] $[\{0\} \subset \{0\}]_K = 1$
    \item [\checkmark (2)] For a hyperplane $W = \{f=0\}$ with $X \subset W \subset V$, $[X \subset V]_K \coloneqq \frac{h_X}{h_V} = \frac{h_X}{h_W} \frac{h_W}{h_V} = [X \subset W]_K [W \subset V]_K$.
    \item[\checkmark (1)] With the setup above, and $X \subset V$, $X \not \subset W$, and $X$ reduced and irreducible, recall that $X = V(I)$ for $I$ a prime ideal $\iff$ $R/I$ is an integral domain.
    
    Letting $h_{X \cap W} \coloneqq h_{R/(I+(f))}$, we have exact sequence
    $$ 0 \to (R/I)f \hookrightarrow R/I \twoheadrightarrow R/(I + (f)) \to 0 $$
    This gives us an injection
    $$ 0 \to R/I \stackrel{\cdot f}{\to} (R/I)f \to 0 $$
    The second map $\cdot f$ above is an isomorphism of $R$-modules, but not in the multigraded sense. To fix this, we must introduce a shift by the weight $[e^{\wt(f)}]$, with $\wt(f) = -\wt(V(f)/W)$.
    Then, we indeed have $[X \subset V]_K = [X \cap W \subset W]_K$, and the axiom holds.
    
    \item[$\bigtimes$ \, (3)] This axiom no longer holds for $[X \subset V]_K$. For example, consider $R = \C[x,y]$, and $I = (x^2 - y^2)$. This is not a prime ideal; we can form quotients by $(x-y)$ or $(x+y)$, obtaining the following short exact sequence of    homogeneous graded $R$-modules:
    $$ 0 \to R/(x^2-y^2) \to R/(x-y) \oplus R/(x+y) \to R/(x,y) \to 0 $$
\centerline{\includegraphics[width=4in]{5.1.jpeg}}

\end{enumerate}
\vspace{1em}
\textbf{Question:} How do we relate $[X \subset V]$ and $[X \subset V]_K$?
\begin{Theorem}
Replace $\lambda$ by $\epsilon \lambda$, and take the leading term. That is:
$$ \lim_{\epsilon \to 0} \left( \frac{[X \subset V]_K}{\epsilon^{\text{codim}_v X}} \right) = [X \subset V] $$
\end{Theorem}

A last definition, which will soon be relevant:

\begin{Definition}[Subword complex]
If $Q$ is a word in the generators of a Coxeter group $W$, with $w \in W$, the subword complex $\Delta(Q,w)$ is a simplicial complex with vertices corresponding to the elements of $Q$.

A subword $F \subset Q$ is called a facet (i.e. a maximal face) precisely when $Q \setminus F$ is a reduced word for $w$.
\end{Definition}

\begin{Example}
Let $r_1$ be the transposition $(12) \in S_n$. Then $\Delta(121, r_1)$ (where $121$ is shorthand for $r_1 r_2 r_1$) is the simplicial complex pictured: \vspace{1em}

\centerline{\includegraphics[width=2in]{5.2.jpeg}}

Note that we index faces and vertices according to ``missing" letters in $Q$, and the complex above is homotopy equivalent to a point. Note also that the unpictured bottom edge, $-2-$ (i.e., $(23)$ in cycle notation), is \textit{not} a facet, because $r_2 = (23)$ is not a reduced word for $r_1$, whereas the other edges yield.
\end{Example}

\section{Lecture 6 (Allen Knutson)}
This lecture is split into two parts.  The first is a continuation of the previous lecture, leading up to an equivariant $K$-theory version of the AJS/Billey formula.  The second is a discussion of $G$-equivariant cohomology from the ground up.

\subsection{The subword complex and equivariant $K$-theory} Recall that given a word $Q$ in the primitive generators of a Coxeter group $W$, and some element $w\in W$, we can build the subword complex $\Delta(Q,w)$. The following theorem gives us a sense of what these look like:

\begin{Theorem}[Knutson-Miller '05] Let $\ell(w)$ denote the length of $w$. Then:
\begin{enumerate}
    \item $\dim \Delta(Q,w) = \# Q - \ell(w) - 1$.
    \item $\Delta (Q,w)$ is always homeomorphic to a ball or a sphere. It is also a $\Delta(Q,w)$ is a \textbf{shellable}  simplicial complex.  
    \item $\partial \Delta(Q,w) = \bigcup_{ w' > w} \Delta(Q,w')$.
\end{enumerate}
\end{Theorem}

We'll mention one other result that tells us something about the combinatorics of these complexes, namely about the links to their faces.

\begin{Example}
First, what's the link of a stratum in a stratified space?  Well, it's the intersection of the boundary of a small open neighborhood of that stratum.  Here's a picture of a link (red) of a stratum (blue), together with the ``combinatorialized'' version of the link available to a simplicial set:
\begin{center}
\includegraphics[width=4in]{6.1.png}
\end{center}
\end{Example}

The result will be stated using the following terminology:
\begin{Definition}
The \textbf{Mobius function} on the faces $F$ of a simplicial complex is
\[ \mu(F) := 1 - \chi(\textup{link of }F)\]
\end{Definition}

\begin{Theorem}
If $\Delta$ is a shellable ball or sphere, then 
    \[ \textup{link}(F) \cong \begin{cases} \textup{hemisphere} & \textup{for $F$ an exterior face}\\
    \textup{sphere} \cong S^{\textup{codim}{F} - 1} & \textup{for $F$ an interior face}\end{cases}\]
Translated, this gives:
\[\mu(F) = \begin{cases} 0 & \textup{for $F$ an exterior face}\\
   (-1)^{\text{codim}(F)}  & \textup{for $F$ an interior face}\end{cases}\]
In our case, where $\Delta = \Delta(Q,w)$, and is thus a shellable ball or sphere, this result implies that $\mu(F) = \pm1$ if $Q \setminus F$ doesn't contain a reduced word $w' \subset w$, and is 0 otherwise.
\end{Theorem}


OK, back to Schubert stuff, where we'll use some of the above terminology. Recall that given $v\in W$ and a reduced word $Q$ for $v$, AJS/Billey gives us a formula

\[ [ X_0^v \cap X_w] = \sum_{\textup{reduced subexpression }R\subseteq Q\\ = \textup{facets of $\Delta(Q,v)$}} stuff \quad \in H_T^*(X_0^v)\]

This is a statement in equivariant cohomology. We will see that there is also an analogous formula in equivariant $K$-theory!  To get there, the above language of the subword complex will be useful, in light of the following result:

\begin{Theorem}[Knutson] There exists a $T$-equivariant degeneration of the Kazhdan-Lusztig variety $X_0^v \cap X_w$ to the Stanley-Reisner variety of the subword complex:
\[ SR(\Delta(Q,w)) := \bigcup_{\textup{facets $F$ of }\Delta(Q,w)} \mathbb{C}^F \quad \subseteq \mathbb{C}^Q\]
\end{Theorem}

The fact that the degeneration is $T$-equivariant means that it drags along equivariant cohomology and $K$-theory classes. So in particular, this result implies the following promised $K$-theory version of AJS/Billey:
\begin{Theorem}[Graham-Willems]
Given $v\in W$ and a reduced word $Q$ for $v$,
\[ [ X_0^v \cap X_w]_K = \sum_{\textup{interior facets of $\Delta(Q,v)$}} (-1)^{|R|-\ell(w)}\Big(\prod_{q\in Q}r_q\cdot  \widehat{(1-e^{-\alpha_q})}\Big)\cdot 1 \quad \in K_T(X_0^v)\]
where the sum is now over subwords $R\subseteq Q$ such that $R$ contains a reduced word for $w$, but not for any $w' > w$; the notation $\widehat{(1-e^{-\alpha_q})}$ means that we only include this expression in the product if $q\in R$. 
\end{Theorem}

The above was about an $T$-equivariant $K$-theory class of an intersection inside the flag variety. Next, we'll have a formula for the $T\times T$-equivariant $K$-theory class of a matrix Schubert variety. Let's first give this a cool name:

\begin{Definition}
The \textbf{double Grothendieck polynomial} is 
\[ G_\pi(e^x, e^y) := [ \overline{X_\pi}]_K \in K_{T\times T}(\textup{Mat}_n) \cong K_{T\times T}(\textup{point}) = \mathbb{Z}[e^{\pm x_1}, \dots, e^{\pm x_n}, e^{\pm y_1}, \dots, e^{\pm y_n}]\]
\end{Definition}

\noindent It turns out that this also has a formula:

\begin{Theorem}[Fomin-Kirillov]
The double Grothendieck polynomial can be calculated as
\[G_\pi(e^x,e^y) = \sum_{\textup{possibly nonreduced pipe dreams for $\pi$}} (-1)^{\# \textup{extra $+$'s}} \prod_{+\textup{'s}} (1-e^{-x_{row} + y_{col}})\]
\end{Theorem}

\begin{Example}
For $\pi = 132$, recall from Lecture 1 that there are two reduced pipe dreams: 

\begin{center}
$\vcenter{\hbox{\begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw (2,3.5) arc[start angle=-90, end angle=0, radius=.5]; %12
\draw (2.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw[-] (1,2.5) to (2,2.5); %21
\draw[-] (1.5,3) to (1.5,2);
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}}}$
\hspace{10mm} and \hspace{10mm}
$\vcenter{\hbox{\begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw[-] (2.5,4) to (2.5,3); %12
\draw[-] (2,3.5) to (3,3.5);
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw (1,2.5) arc[start angle=-90, end angle=0, radius=.5]; %21
\draw (1.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}}}$
\end{center}
\vspace{5mm}

There is also one (properly) nonreduced pipe dream, with two crossings, which is resolved by the above reduced two:

\begin{center}
    \begin{tikzpicture}
\draw[-] (1,4) to (4,4);
\draw[-] (4,4) to (4,1);
\draw[-] (4,1) to (1,1);
\draw[-] (1,1) to (1,4);
\node (1) at (1.5,4.5) {$1$};
\node (2) at (2.5,4.5) {$2$};
\node (3) at (3.5,4.5) {$3$};
\node (p1) at (0,3.5) {$1$};
\node (p2) at (0,2.5) {$3$};
\node (p3) at (0,1.5) {$2$};
\draw[-] (2,4) to (2,1);
\draw[-] (3,4) to (3,1);
\draw[-] (4,4) to (4,1);
\draw[-] (1,1) to (4,1);
\draw[-] (1,2) to (4,2);
\draw[-] (1,3) to (4,3);
\draw[-] (1,4) to (4,4);
\draw (1,3.5) arc[start angle=-90, end angle=0, radius=.5]; %11
\draw (1.5,3) arc[start angle=180, end angle=90, radius=.5]; 
\draw[-] (2.5,4) to (2.5,3); %12
\draw[-] (2,3.5) to (3,3.5);
\draw (3,3.5) arc[start angle=-90, end angle=0, radius=.5]; %13
\draw (3.5,3) arc[start angle=180, end angle=90, radius=.5];
\draw[-] (1,2.5) to (2,2.5); %21
\draw[-] (1.5,3) to (1.5,2);
\draw (2,2.5) arc[start angle=-90, end angle=0, radius=.5]; %22
\draw (2.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (3,2.5) arc[start angle=-90, end angle=0, radius=.5]; %23
\draw (3.5,2) arc[start angle=180, end angle=90, radius=.5];
\draw (1,1.5) arc[start angle=-90, end angle=0, radius=.5]; %31
\draw (1.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (3,1.5) arc[start angle=-90, end angle=0, radius=.5]; %32
\draw (2.5,1) arc[start angle=180, end angle=90, radius=.5];
\draw (2,1.5) arc[start angle=-90, end angle=0, radius=.5]; %33
\draw (3.5,1) arc[start angle=180, end angle=90, radius=.5];
\end{tikzpicture}
\end{center}

Therefore, by the Fomin-Kirillov formula, the double Grothendieck polynomial in this case is
\[ G_{132}(e^x, e^y) = (1-e^{-x_2 + y_1}) + (1-e^{-x_1 + y_2}) - (1-e^{-x_2 + y_1})(1-e^{-x_1 + y_2})\]
\end{Example}



\subsection{$G$-equivariant cohomology: what is it, really?}
Okay, changing gears! We've already seen some $G$-equivariant cohomology (and even some $G$-equivariant $K$-theory), but let's dive into the details a bit.

We all love integral cohomology. It's our favorite (contravariant) functor 
\[H^*: \frac{\{\textup{spaces, continuous maps}\}}{\textup{homotopy}} \to \textup{Rings}\]
Fixing a group $G$, we might wish to build a version of $H^*$, which we'll denote $H^*_G$, that goes like:
\[H_G^*: \frac{\{\textup{$G$-spaces, continuous $G$-equivariant maps}\}}{\textup{$G$-equivariant homotopy}} \to \textup{Rings}\]
In other words, we're shopping for some kind of topological invariant of $G$-spaces that is sensitive to the action itself (even though, confusingly, the action is not reflected in the notation ``$H_G^*$'' that we've chosen). Let's demand a few properties from $H_G^*$:
\begin{enumerate}
    \item if the $G$-action on $X$ is free, then $H_G^*(X) \cong H^*(X/G)$;
    \item if the $G$-space $C$ is contractible (but not necessarily $G$-equivariantly contractible), then $H_G^*(X \times C) \cong H_G^*(X)$, where the $G$-action on the product is the diagonal one.
\end{enumerate}
These are in fact a complete list of axioms of the theory.  Indeed, if $EG$ denotes any contractible space on which $G$ acts freely, then by (1) and (2) we have 
\[ H_G^*(X) \cong H_G^*(X\times EG) \cong H^*( (X\times EG)/G).\]
So we can calculate the equivariant cohomology of any $G$-space as the \textit{usual} cohomology of the \textbf{Borel mixing space} $(X\times EG)/G$ of the action. This space looks like an $X$-bundle over $EG/G =: BG$. 

To make use of this new invariant, we'll first need to build some $EG$'s. Let's do a few:

\begin{Example}
If $G=\Z$, we can take $E\Z := \mathbb{R}$ with the translation action. So $B\Z = S^1$.
\end{Example}

\begin{Example}
This will be the most important example for us. If $G=\mathbb{C}^\times$, we can take $E\mathbb{C}^\times := \mathbb{C}^\infty \setminus \{0\}$ with the diagonal action.  This space is contractible by a theorem in topology. By taking products, we get that we can take $E(\mathbb{C}^\times)^d := (E\mathbb{C}^\times)^d$. Another thing: since $B\mathbb{C}^\times \cong \mathbb{C}P^\infty$, we see that even the equivariant cohomology of a point can be huge: $H_{\mathbb{C}^\times}^*(\textup{point}) = H^*(\mathbb{C}P^\infty) = \mathbb{Z}[u], |u|=2$.
\end{Example}


\begin{Example}
If $G=GL_n\mathbb{C}$, we can take
\[ EGL_n\mathbb{C} := \{ n \times \mathbb{N} \textup{ matrices of rank $n$}\}\]
Repeatedly extracting the bottom row realizes $EGL_n\mathbb{C}$ as an iterated $(\mathbb{C}^\infty \setminus \{0\})$-bundle over $\mathbb{C}^\infty \setminus \{0\}$, and therefore it is contractible.

It's not so important that we know this example.  But since we do now, we can get a bunch of $EG$'s for free from the following simple observation: if $G\leq H$ is a subgroup, then $EH$ can serve as an $EG$!  So if $G \leq GL_n\mathbb{C}$ is any matrix group, we can just steal $EGL_n\mathbb{C}=:EG$.
\end{Example}

\begin{Remark}
If $G\leq H$ is a homotopy equivalence, then $H^*_G = H^*_H$. We will use this for a torus $T$ inside the Borels $B,B_-$.
\end{Remark}

\begin{Remark}
If $Y \subset X$ is a nice $G$-stable subset, then hopefully it's believable that it defines a class $[Y]_G \in H^*_G(X)$. We'll drop the subscript $G$ when it should be clear that something lives in equivariant cohomology. For example, both $[X_w^\circ]$ and $[X_w]$ refer to honest classes in $H_{B_-}^*(GL_n/B)$.
\end{Remark}

We'll calculate more with this later, but for now we'll take the $GL_n\mathbb{C}$-equivariant inclusion \fbox{$j: GL_n\mathbb{C} \hookrightarrow \textup{Mat}_n\mathbb{C}\simeq \textup{point}$} and extract a diagram that relates the classes we've encountered so far:

\begin{center}
\begin{tikzcd}
& & & \mathbb{Z}[x_1, \dots, x_n, y_1, \dots, y_n]\arrow[d,equals]\\
H^*_{B_-}(GL_n/B) & H^*_{B_-\times B}(GL_n)\arrow[l,equals] & H^*_{B_-\times
B}(\textup{Mat}_n\mathbb{C})\arrow[l,"j^*"'] \arrow[r,equals] & \overbrace{H^*_{T\times T}(\textup{point})}\\
\left[X_\pi\right] & \left[\overline{B_- \pi B}\right]\arrow[l,equals] & \left[\overline{\overline{B_- \pi B}}=: \overline{X_\pi}\right]\arrow[l,mapsto] & S_\pi (x,y)\arrow[l,equals]
\end{tikzcd}
\end{center}

Here is one more diagram that we can draw: for $v\in S_n$, there is the sequence of $T$-equivariant inclusions \fbox{$i_v: vB/B \hookrightarrow X_0^v \hookrightarrow GL_n/B$}, which gives

\begin{center}
    \begin{tikzcd}
    H_T^*(\textup{point}) \cong \mathbb{Z}[y_1, \dots, y_n]\arrow[d,equals] & & \\
    \overbrace{H^*_T(vB/B)} & H^*_T(X_0^v)\arrow[l,"i_v^*"'] & H_{T\simeq B_-}(GL_n/B)\arrow[l,"i_{X_0^v}^*"']\\
    \left[X_w\cap X_0^v\right]\big|_v \arrow[d,equals] & \left[X_w\cap X_0^v\right]\arrow[l,mapsto] & \left[X_w\right]\arrow[l,mapsto]\arrow[d,equals]\\
    S_w(x,y)|_{x_i := y_{v(i)}} & & S_w(x,y)
    \end{tikzcd}
\end{center}
This is a factorization of the map that just restricts to the $T$-fixed point $vB/B \in GL_n/B$.

\section{Lecture 7 (Paul Zinn-Justin)}

\section{Lecture 8 (Paul Zinn-Justin)}

\section{Lecture 9 (Allen Knutson)}

\section{Lecture 10 (Allen Knutson)}

\section{Lecture 11 (Paul Zinn-Justin)}
We recall the following equivalent ways to express elements of the Grassmanian:
\begin{center}
	\begin{tabular}{ |c |c| }
		\hline
		Gr$(k,n)$ & $k=3$ $n=5$ example \\ \hline
		$k$-subsets of $\lbrace 1,\dots,n\rbrace$ & $\lbrace 1,3,5\rbrace$ \\ 
		Binary strings with content $0^k/1^{n-k}$ & $01010$ \\  
		Inverses of Grassmanian permutations & $14253$ \\
		\hline 
	\end{tabular}
\end{center}
Diagrammatically we express this as:
\begin{center}
	\begin{tikzcd}
		0 \arrow[dd] & 1 \arrow[rdd] & 0 \arrow[ldd] & 1\arrow[rdd] & 0  \arrow[ldd] & \textcolor{red}{=\mu}\\
		&&&&& \textcolor{red}{=w}\\
		0 & 0 & 0 & 1 & 1 & \textcolor{red}{=w(\mu)}
		
	\end{tikzcd}
\end{center}
We also recall the $\check{R}$-matrix expression
\begin{align*}
	&&\check{R}_i(u)&=\underbrace{1\otimes\dots\otimes 1}_\text{$i+1$}\otimes \left(\begin{array}{cccc}
		1 &  & &  \\
		&  1 & & \\
		& u& 1 & \\
		& & & 1
	\end{array} \right)\otimes\underbrace{1\otimes\dots\otimes 1}_\text{$n-i-1$}.&
\end{align*}
We wish to consider the expansion of $s_iS_\lambda$ into $S_\mu$: $\check{R}_i(y_i-y_{i+1})=\check{R}^{(s_i)}$. We have
\begin{align*}
	&&\int \Tilde{S}_\lambda S_\mu&=\delta_{\lambda\vec{\mu}}&
\end{align*}
where $\Tilde{S}_\lambda$ denotes the class of the Schubert cell opposite to $S_\lambda$ and
\begin{align*}
	&& S_\lambda&=S_\lambda^{(1)}, & \Tilde{S}_\lambda&=S^{(w_0)}_\lambda.&
\end{align*}
A diagrammatic example for the permutation 231 is given by
\begin{center}
	\begin{tikzcd}
		&y_1 \arrow[ddr]& y_2\arrow[ddr]& y_3 \arrow[ddll]\\
		\Check{R}^{(231)}= &{}&{}&\\
		&{}&{}& {}
	\end{tikzcd}
\end{center}
For $w\in S_n$ we have
\begin{align*}
	&&\Check{R}_{\lambda\mu}^{(w)}&=\int (w\Tilde{S}_\lambda)S_\mu&
\end{align*}
and we wish to know for example whether
\begin{align*}
	&&\Check{R}^{(\underline{231})}&\stackrel{?}{=} \Check{R}^{(s_1)} \Check{R}^{(s_2)}&
\end{align*}
where $(\underline{231})=s_1s_2$. Letting $\tau_i: y_i\leftrightarrow y_{i+1}$ we have
\begin{align*}
	&&\tau_1\Check{R}^{(s_1)}\tau_2\Check{R}^{(s_2)}&=\tau_1\Check{R}_1(y_2-y_1)\tau_2\Check{R}_2(y_3-y_2)&\\
	&&&=\tau_1\tau_2\Check{R}_2(y_3-y_1)\Check{R}_2(y_3-y_2).&
\end{align*}
Now letting
\begin{align*}
	&&f&=\sum_\lambda a_\lambda S_\lambda, &a_\lambda\in H_T
\end{align*}
we have
\begin{align*}
	&&s_if&=\sum_\lambda(\tau_i\alpha_\lambda)s_iS_\lambda&
\end{align*}
where the action of $s_i$ on $(H_T^*(\mathrm{Gr}),S_\lambda)$ is 
\begin{align*}
	&&\Check{R}_i(y_i-y_{i+1})\tau_i&=\tau_i\Check{R}_i(y_{i+1}-y_i)&
\end{align*}
by the action of $s_i$ on the base ring $H_T^*$. The relations of $S_n$ also give us
\begin{align*}
	&&\tau_i\Check{R}_i(y_{i+1}-y_i)&=\tau_i\Check{R}_i(y_{i+1}-y_i)\tau_i \Check{R}_i(y_{i+1}-y_i)&\\
	&&&=\tau_i^2\Check{R}_i(y_{i+1}-y_i)\Check{R}_i(y_{i+1}-y_i)&\\
	&&&=1&
\end{align*}
which is equivalent to the following diagrammatic relation:
\begin{center}
	\begin{tikzpicture}
		\pic[
		braid/.cd,
		number of strands = 2,
		every strand/.style={ultra thick,->},
		strand 1/.style={black},
		name prefix=braid,
		] {braid={ s_1s_1^{-1} }};
		\node[circle,fill=white, inner sep = 2pt] at (braid-1-0) {$y_i$};
		\node[circle,fill=white, inner sep = -1pt] at (braid-2-0) {$y_{i+1}$};
	\end{tikzpicture} = 
	\begin{tikzpicture}
		\pic[
		braid/.cd,
		number of strands = 2,
		every strand/.style={ultra thick,->},
		strand 1/.style={black},
		name prefix=braid,
		] {braid={ 11 }};
		\node[circle, fill=white, inner sep = 2pt] at (braid-1-0) {$y_i$};
		\node[circle, fill=white, inner sep = -1pt] at (braid-2-0) {$y_{i+1}$};
	\end{tikzpicture}
\end{center}
We also have the Yang-Baxter equation:

\begin{center}
	\begin{tikzpicture}
		\pic[
		braid/.cd,
		number of strands = 3,
		every strand/.style={ultra thick,->},
		strand 1/.style={black},
		name prefix=braid,
		] {braid={ s_1s_2 s_{1,2} }};
		\node[circle,fill=white, inner sep = 2pt] at (braid-1-0) {$y_i$};
		\node[circle,fill=white, inner sep = -1pt] at (braid-2-0) {$y_{i+1}$};
		\node[circle,fill=white, inner sep = -1pt] at (braid-3-0) {$y_{i+2}$};
	\end{tikzpicture} = 
	\begin{tikzpicture}
		\pic[
		braid/.cd,
		number of strands = 3,
		every strand/.style={ultra thick,->},
		strand 1/.style={black},
		name prefix=braid,
		] {braid={ s_{2,3} s_1 s_2 }};
		\node[circle, fill=white, inner sep = 2pt] at (braid-1-0) {$y_i$};
		\node[circle, fill=white, inner sep = -1pt] at (braid-2-0) {$y_{i+1}$};
		\node[circle, fill=white, inner sep = -1pt] at (braid-3-0) {$y_{i+2}$};
	\end{tikzpicture}
\end{center}
which may be expressed algebraically as:
\begin{align*}
	&&\Check{R}_i(y_{i+2}-y_{i+1})\Check{R}_{i+1}(y_{i+2}-y_i)\Check{R}_i(y_{i+1}-y_i)&=\Check{R}_{i+1}(y_{i+1}-y_i)\Check{R}_i(y_{i+2}-y_i)\Check{R}_{i+1}(y_{i+2}-y_{i+1}).&
\end{align*}
For an arbitrary permutation $w$ we may also write
\begin{center}
	\includegraphics[]{lecture_diagrams_cropped_1.png}
\end{center}
With these we now give a reinterpretation of the AJS-Billey formula. First we let
\begin{align*}
	&&[\lambda]&=\sum a_{\lambda\mu} S_\mu,& a_{\lambda\mu}&=\int \Tilde{S}_\mu[\lambda].&
\end{align*}
Then we have
\begin{align*}
	&&S_\lambda|_\mu&=\int S_\lambda[\mu]&\\
	&&&=\int S_\lambda w\Tilde{S}_{0\dots0 1\dots 1}&\\
	&&&=\Check{R}^{(w)}_{0\dots01\dots 1,\lambda}&
\end{align*}
where $[1\dots 10\dots 0]=S_{1\dots 10\dots 0}$, $[0\dots01\dots 1]=\Tilde{S}_{0\dots01\dots1}$ and $w\in S_n$ is such that $[\mu]=w[0\dots01\dots1]$. That is, $w$ is the permutation which pushes all of the 1s in the binary string expression for $[\mu]$ to the right. Diagrammatically we express this operation by
\begin{center}
	\includegraphics[scale=0.75]{lecture_diagrams_cropped_2.png}
\end{center}
To express these ideas with transfer matrices we use a correspondence whereby


\begin{align*}
	&&H_T^*(\mathrm{Gr}(\cdot,n))\otimes\C&\cong (\C^2)^{\otimes n}[y_1,\dots,y_n]&\\
	&&S_\lambda& \leftrightarrow \bigotimes_{i=1}^n\begin{cases} 
\begin{pmatrix}
	0 \\
	1  
\end{pmatrix}, & \lambda_i=1, \quad \color{red}\dotfill \\
\begin{pmatrix}
	1 \\
	0  
\end{pmatrix}, & \lambda_i=0,\quad \ \color{blue}{1} 
\end{cases}
\end{align*}
where $\mathrm{Gr}(\cdot,n)=\lbrace V\subset\C^n\mid \text{ $V$ a linear subspace}\rbrace$. The transfer matrix
\begin{center}
	\includegraphics[]{lecture_diagrams_cropped_3.png}
\end{center}
with $\left(\begin{array}{cc}
	A & B \\
	C & D
\end{array}\right)\in\mathrm{End}( H_T^*(\mathrm{Gr}(\cdot,n))[u]$ preserves each $H_T^*(\mathrm{Gr}(k,n))$.
\begin{center}
	\includegraphics[scale=0.8]{lecture_diagrams_cropped_4.png}
\end{center}
Finally, with $\mu=w[0\dots01\dots1]$ we have
\begin{center}
	\includegraphics[]{lecture_diagrams_cropped_5.png} \\
	\includegraphics[]{lecture_diagrams_cropped_6.png}
\end{center}
which gives us our reinterpretation of the AJS-Billey formula.

\section{Lecture 12 (Paul Zinn-Justin)}
    Define $f$ as follows:
\begin{align*}
    f:\Gr(k,n)&\to\Gr(k+1,n+1), \\
    V&\mapsto V\oplus\C
\end{align*}
where $\C$ is the $n$'th coordinate subspace and $\C^{n+1}=\C^n\oplus\C$.
Define
\begin{align*}
    T'=(\C^\times)^{n+1}\subset\GL(n+1)
\end{align*}
where $T=(\C^\times)^n$. The symmetrizer of $T'$ is $\Sym T'=\Z[y_1,\ldots,y_n,u]$. Then define
\begin{align*}
    f^\star:H_{T'}(\Gr(k+1,n+1))]\to H_{T'}(\Gr(k,n)).
\end{align*}
Then $D(u)=f^\star f_\star$. Note that $f^\star$ is surjective. Let $x\in H_{T'}^\star(\Gr(k,n))$ and $y\in H_{T'}(\Gr(k+1,n+1))$ where $x=f^\star y$. Then
\begin{align*}
    D(u)x = f^\star(f_\star f^\star y) = f^\star(yf_\star 1) = (f^\star f_\star 1)\times\C\in H_{T'}(\Gr(k,n)).
\end{align*}
Consider $\C^I$ where $I$ is a $k$-subset of $\{1,\ldots,n\}$. Then $[\mu]\stackrel{f_\star}{\mapsto}[\C^{I\cup\{n\}}]\stackrel{f^{-1}}{\to}[\C^I]$. Note that $\{\C^{I\cup\{n+1\}}\}\cap:\Gr(k,n)$, meaning this intersection is not transverse.

For $\varphi\in H_{T'}(\pt)=\Z[y_1\ldots,y_n,u]$, we have $\deg(\varphi)=\codim\Gr(k,n)\subset\Gr(k+1,n+1)$. We have that $T''\subset T'$ is the line of fixed points going through $\Gr(k,n)$ and $\C^{I_1I_2\cdots I_k}=\spn(e_{I_1},\ldots,e_{I_k},\sum e_j)$. Finally,
\begin{align*}
    \varphi(u) = \prod_{j\notin I}(u-y_i).
\end{align*}

Note that pipe dreams and puzzles have different lattice models. Pipe dreams have two labels ($0$, $1$) whereas puzzles have three labels ($0$, $1$, $10$). Considering the product of two Schubert classes $S^\lambda S^\mu$, we have
\begin{align*}
    S^\lambda S^\mu = \sum_\nu c_\nu^{\lambda\mu} S^\nu\in H_T(\pt).
\end{align*}
For all $w\in W_p/W$ (where $W_p=\cS_n\times\cS_{n-k}$ and $W=\cS_n$), we have
\begin{align*}
    S^\lambda|_wS^\mu|_w = \sum_\nu c_\nu^{\lambda\mu}S^\nu|_w.
\end{align*}
Our puzzle pieces are all the rotations of three triangles as well as one rhombus, called the equivariant tile, which may not be rotated: \ctikzfig{Tiles}

Encoding the partitions $\lambda$, $\mu$ and $\nu$ with $\{0,1\}$-strings, we fill in a puzzle corresponding to $c_\nu^{\lambda\mu}$ as follows: \ctikzfig{Puzzle}

Then $\Rcheck$ is a $9\times9$ matrix in $\End(\C^3\otimes\C^3)$.
\begin{align*}
    \tikz[baseline=6]{\draw(0,0)node[below]{$y_i$}--++(1,1);\draw(1,0)node[below]{$y_j$}--++(-1,1)} &=
    \tikz[baseline=16]{\draw(0,0)--++(1/2,1/2)--++(0,1/2)--++(-1/2,1/2);\draw(1/2,1)--++(1/2,1/2);\draw(1/2,1/2)--++(1/2,-1/2)} +
    (y_i-y_j)
    \tikz[baseline=6]{\draw(0,0)node[below]{$1$}--++(1,1)node[above]{$1$};\draw(1,0)node[below]{$0$}--++(-1,1)node[above]{$0$}} \\
    \cup &=
    \tikz[baseline=6]{\draw[>-](0,1)--++(1/2,-1/2);\draw[>-](1,1)--++(-1/2,-1/2);\draw[->](1/2,1/2)--++(0,-1/2)}
    \in \Hom(\C^3\otimes\C^3,\C^3)
\end{align*}
and $c_\nu^{\lambda\mu}=\langle\nu\mid\cup_1\cdots\cup_n\underbrace{\Rcheck\cdots\Rcheck(y_1-y_n)}_{\binom{n}{2}\text{ of these}}\mid\lambda\otimes\mu\rangle$. Note that if we glue the triangles along their $10$ labels they form a rhombus. Then assign a perpendicular unit vector to the $1$ labels in each tile as follows: \ctikzfig{TileVectors}

Next consider filling a triangle puzzle with the tiles. We have the following lemma.
\begin{Lemma}
    The boundary of a puzzle has vector sum zero.
\end{Lemma}
\begin{proof}
    Each tile has vector sum of zero, so a valid filling must have vector sum zero. When tiles meet internally, their vectors cancel so internal edges have vector sum zero. Thus, the vector sum of the boundary must also be zero; this means that each face of the triangle contains the same number of $0$'s and $1$'s.
\end{proof}

\section{Lecture 13 (Allen Knutson)}


Historical round up of the names whose work leads to understanding what the $6$ vertex puzzles were solving:
\begin{itemize}
	\item (Jimbo/Drinfeld '80s): $R$-matrices from representation theory of quantized loop algebras $U_q(\delta[z^\pm])$
	\item (Nakajima '01): some representations of $U_q(\delta[z^\pm])$ acting on $K(\text{quiver schemes})$ (think $\text{quiver schemes} = \bigsqcup \text{ quiver varieties}$)
	\item (Varagnolo '01): same thing in cohomology
	\item (Maulik-Okounkov '12): $R$-matrices "from" quiver schemes
\end{itemize}

\begin{Example}
	$\text{T}^* \Gr(k, \C^n)$ are Nakajima quiver varieties
\end{Example}

Note that quiver varieties and cotangent bundles of manifolds are always symplectic manifolds.
But quiver varieties are cotangent bundles \textbf{only} as cotangent bundles of flag manifolds or their products.

We will be working in $H^*_{T\times \C^\times} (\text{T}^* \Gr(k, \C^n))$ where the $\C^\times$ factor acts by dilation on the fibers. Note that we have
\[
	H^*_{T\times \C^\times} (\text{T}^* \Gr(k,\C^n)) \cong H^*_{T\times \C^\times} (\Gr(k,\C^n)) \cong H^*_{T} (\Gr(k,\C^n)) [\hbar]
\]
since $\text{T}^* \Gr(k,\C^n)$ and $\Gr(k,\C^n)$ are homotopy equivalent.

So although we have the Schubert basis, we will be working with a different basis.
In particular, we will be using specific subvarieties in $\text{T}^* \Gr(k,\C^n)$ that are not the Schubert varieties. However, as we shall see, taking the leading term with respect to $\hbar$ in the new basis will correspond to taking the Schubert classes.

\begin{Definition}
	To a locally closed submanifold $A \subsetneq M$ (e.g. Schubert cells) we associate its conormal bundle $C_A M \subset \text{T}^* M$ defined by

	\begin{center}
		\begin{tikzcd}
			C_A M \arrow[r, phantom, sloped, "\subseteq"] \arrow[d, equals] & \text{T}^* M \arrow[d, equals] \\
			\{(m,\overrightarrow{v}) : m\in A, \overrightarrow{v}\perp \text{T}_m A\}                                                & \{(m,\overrightarrow{v}): m\in M,\overrightarrow{v} \in \text{T}_m^* M \}
		\end{tikzcd}
	\end{center}
\end{Definition}

Note that $\dim C_A M = \dim M$.

Recall that for a continuous map $f: M\to N$ we get a map $\text{T} f : \text{T} M \to \text{T} N$, but \textbf{not} a map $\text{T}^* f : \text{T}^* M \to \text{T}^* N$. We wish to rectify this as follows:
\begin{Definition}
	The "category" of ({\color{red} symplectic}) manifolds \& ({\color{red} Lagrangian}) correspondences has objects - compact oriented manifolds and  morphisms - $\Hom(M,N) := \{ \text{ oriented cycles } L\subseteq M \times N\}$.
	(cycles in the sense of formal linear combinations)
\end{Definition}

\begin{Example}
	To a function $f:M \to N$ we can assign its graph,
	\[ \text{graph}(f) = \{(m, f(m)) : m \in M\} \subseteq M \times N.
	\]
\end{Example}

We define composition in our "category" as follows:

\begin{center}
	\begin{tikzcd}
		&                         & L \star K \arrow[ld] \arrow[rd] &                         &   \\
		& L \arrow[ld] \arrow[rd] &                         & K \arrow[ld] \arrow[rd] &   \\
		M &                         & N                       &                         & P
	\end{tikzcd}
\end{center}
where $L\star K \coloneqq L \times_N K = \{ (m,p) \in M\times P: \exists n\in N, (m, n) \in L, (n,p) \in K\}$.

Note that although $L\star K$ works as a set, it might \textbf{not} be a submanifold, hence why we say "category" and only consider compositions when they make sense.

\textbf{Why is this "category" worth understanding?}

Consider the functor $H_*$ (or $H^*$) from the category of compact oriented manifolds to inner product spaces.

Note that the category of inner product spaces has a notion of transpose, while the category of compact oriented manifolds does not. We attempt to fix this by introducing our "category" which has a transpose $(L \subseteq M\times N) \mapsto (L^T \subseteq N\times M)$. In fact, we see that $H_*$ factors through our "category" in the following way:

\begin{center}
	\begin{tikzcd}
		\left \{ \parbox{8em}{compact oriented manifolds \& functions} \right \} \arrow[rrrr,"H_*(\text{or } H^*)"] \arrow[rrd, "\text{graph}(\cdot)"] &  &               &  & \left \{ \parbox{8em}{inner product spaces} \right \} \\
		&  & \left \{ \parbox{8em}{compact oriented manifolds \& correspondences} \right \} \arrow[rru,"\beta"] &  & (\beta_L : H^*(M) \to H^*(N)) \\
		&  & L\in \Hom(M, N) \arrow[rru, mapsto]            &  &
	\end{tikzcd}
\end{center}

Where to define $\beta_L$, we consider the projections:
\begin{center}
	\begin{tikzcd}
		& M\times N \arrow[ld, "\pi_M"'] \arrow[rd,"\pi_N"] &   \\
		M &                         & N
	\end{tikzcd}
\end{center}
so that
\[
	\beta_L(m) \coloneqq (\pi_N)_*([L] \cup \pi_M^*(m))
\]

To see when $\beta$ works well with compositions, we require that $\int_N (L\times P) \pitchfork (M\times K)$, i.e.
\begin{itemize}
	\item $L\times P$ intersects transversally with $M\times K$ in $M\times N\times P$
	\item the image of $(L\times P) \cap (M\times K)$ in $N$ under projection is generically finite-to-one
\end{itemize}
in which case $\beta_{L \star K} = \beta_{K} \circ \beta_{L}$.


\begin{Remark}
	\[
		(\beta_{\text{graph}(f)})^T = f_* : H_*(M) \to H_*(N)
	\]
	where $f:M \to N$ is a function and $(\cdot)^T$ denotes the transpose.
\end{Remark}

What Alan Weinstein focused on is {\color{red} symplectic} manifolds and {\color{red} Lagrangian} correspondences.

In such cases, $C_A M$ is Lagrangian and whenever \[
	\int_N (L\times P) \pitchfork (M\times K)
\] holds, then $L \star K$ is Lagrangian.

Much less obvious is that $L \star K$ is a Lagrangian variety even without the transversality conditions. (reference needed)

\begin{Question}
	Let $f : M \to N$, prove that the following diagram commutes:

	\begin{center}
		\begin{tikzcd}
			\text{T}^* N \arrow[r]           & \text{T}^* M           \\
			N \arrow[r,"(\text{graph}(f))^T"] \arrow[u,"\text{graph}(\eta_N)"] & M \arrow[u,"\text{graph}(\eta_M)"']
		\end{tikzcd}
	\end{center}
	where $\eta_N,\eta_M$ denote the zero section functions.
\end{Question}

\section{Lecture 14 (Paul Zinn-Justin)}

\subsection{Basic Definitions}

\begin{Definition}[Temperley-Lieb Algebra]
	Let $\tau$ be a complex number. The \textbf{Temperley-Lieb algebra} $\TeL_n(\tau)$ is generated by an identity $1$ and generators $e_1, \ldots e_{n-1}$ satisfying the relations
	\begin{itemize}
		\item $e_i^2 = \tau e_i$
		\item $e_i e_{i+1} e_i = e_i$
		\item $e_i e_j = e_j e_i, |i-j|>1$
	\end{itemize}
\end{Definition}

We can give a pictorial description of this algebra: we regard each generator $e_i$ as corresponding to a diagram
\ctikzfig{TLfig1}
and regard $\tau$ as corresponding to the ``fugacity of a bubble." We then multiply by composing vertically (with the rightmost element at the top), and ``popping" bubbles to obtain a factor of $\tau$:
\ctikzfig{TLfig2}

\begin{Example}[$\TeL_3(\tau)$]
	When $n=3$, we have generators $1 = $ \tikzfig{TL3gen1}, $e_1 = $ \tikzfig{TL3gene1}, and $e_2 = $ \tikzfig{TL3gene2}. We also obtain
	\[e_1 e_2 = \tikzfig{TL3e1e2}\]
	and 
	\[e_2 e_1 = \tikzfig{TL3e2e1},\]
	so that $\TeL_3(\tau)$ is $5$-dimensional.
\end{Example}



\begin{Proposition}
	The dimension of $\TeL_n$ is
	\[\dim \TeL_n = C_n = \frac{(2n)!}{n!(n+1)!},\]
	the $n$th Catalan number.
\end{Proposition}

\subsection{Temperley-Lieb Algebras and the Yang-Baxter Equation} We can reinterpret the Yang-Baxter equation through the lens of Temperley-Lieb algebras. Let $\tau = -(q+q^{-1}), a(u) = qu-q^{-1}u^{-1},$ and $b(u) = u-u^{-1}.$ We can then regard $\Rcheck_i$ as an element of the algebra obtained by adding $u^\pm$ and $v^\pm$ to $\TeL_n(\tau)$:
\[\Rcheck_i(u) = a(u) 1 + b(u) e_i \in \TeL_n(\tau)[u^{\pm}, v^{\pm}].\]
One can check that the equation
\[\Rcheck_i(u) \Rcheck_{i+1}(uv) \Rcheck_i(v) = \Rcheck_{i+1}(v) \Rcheck_{i}(uv) \Rcheck_{i+1}(u)\]
holds; we may thus interpret the Yang-Baxter equation as an identity in $\TeL_n(\tau)[u^{\pm}, v^{\pm}].$

Via this identification, we can regard systems satisfying the Yang-Baxter equation as representations of this algebra $\TeL_n(-(q+q^{-1}))[u^{\pm}, v^{\pm}].$ We may obtain one such representation via the map 
\[\phi: \TeL_n(-(q+q^{-1})) \rightarrow \on{End}((\C^2)^{\otimes n})\]
sending
\[e_i \mapsto I \otimes I \otimes \ldots \otimes  I \otimes 
\begin{bmatrix}
	0 & 0 & 0 & 0\\
	0 & -q^{-1} & 1 & 0\\
	0 & 1 & -q & 0\\
	0 & 0 & 0 & 0
\end{bmatrix} \otimes I \otimes \ldots \otimes I,\]
where the matrix is located in the $i$ and $i+1$ coordinates. 

One can check that this map respects the Temperley-Lieb relations, and that it induces a representation $\rho: \TeL_n(-(q+q^{-1}))[u^{\pm}, v^{\pm}] \rightarrow \on{End}((\C^2)^{\otimes n})$ sending
\[\Rcheck_i(u) \mapsto I \otimes \ldots \otimes  I \otimes 
\begin{bmatrix}
	qu-q^{-1}u^{-1} & 0 & 0 & 0\\
	0 & u(q-q^{-1}) & u-u^{-1} & 0\\
	0 & u-u^{-1} & u^{-1}(q-q^{-1})& 0\\
	0 & 0 & 0 & qu-q^{-1}u^{-1}
\end{bmatrix} \otimes I \otimes \ldots \otimes I\]

\subsection{Loop Models}

\begin{Definition}[Loop Model]
	A \textbf{loop model} is an assignment of the tiles \tikzfig{LoopModelPiece1} and \tikzfig{LoopModelPiece2} to the $k \times n$ rectangle
	\ctikzfig{LoopModelRectangle}
\end{Definition}

We can compute the \textbf{fugacity} of a loop model with respect to a parameter $q \not = \pm 1$ by assigning a fugacity of $a(x_i/y_j)$ to the \tikzfig{LoopModelPiece1} tile, and $b(x_i/y_j)$ to the \tikzfig{LoopModelPiece2} tile, and multiplying by $\tau^{\#\text{ closed loops}}$, where $\tau = -(q+q^{-1})$. That is, the fugacity is
\[\tau^{\#\text{ closed loops}} \cdot \prod_{i=1}^{k}\prod_{j=1}^n
\begin{cases}
	a(x_i/y_j) & \tikzfig{LoopModelPiece1}\\
	b(x_i/y_j) & \tikzfig{LoopModelPiece2}
\end{cases}\]

When $q = \pm 1$, we instead assign weights of $a(x_i -y_j)$ and $b(x_i-y_j)$ respectively, so that the fugacity of the loop model is

\[\tau^{\#\text{ closed loops}} \cdot \prod_{i=1}^{k}\prod_{j=1}^n
\begin{cases}
	a(x_i - y_j) & \tikzfig{LoopModelPiece1}\\
	b(x_i - y_j) & \tikzfig{LoopModelPiece2}
\end{cases}\]

%Add a worked example of fugacity computation.

\subsection{Loop Models and Grassmannians}

Let $X = T^*\Gr(k, n)$ be the cotangent bundle of the Grassmannian. We wish to consider its $T \times \C^\times$-equivariant cohomology. Observe that
\[H_{T \times \C^\times}^*(X) \cong \Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k}/\cI,\]
where:

\begin{itemize}
	\item The ring $\Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k}$ consists of polynomials symmetric in the $x_i$, i.e., invariant under the action of $S_k$ on $x_1, \ldots, x_k$. \item $\cI$ is the ideal generated by polynomials which vanish when each $x_i$ is replaced by some (distinct) $y_j$. 
	%is this actually correct? I have in my notes that $\cI = \cap \ker \phi_I,$ but I'm not sure that agrees with the example PZJ gave for $k=1$.
	That is, for any $I \in \binom{[n]}{k}$, we can define a map 
	\[\phi_I: \Z[x_1, \ldots, x_k, y_1, \ldots, y_n, h]^{S_k} \rightarrow \Z[y_1, \ldots y_n, h]\] 
	which sends $p(x_1, x_2, \ldots, x_k, y_1, \ldots, y_n, h)$ to $p(y_{I_1}, y_{I_2}, \ldots, y_{I_k}, y_1, \ldots, y_n, h).$ Note that the order on the elements of $I$ does not matter, since $p$ is symmetric in the $x_i.$ Then $\cI$ is the ideal generated by the kernels of the $\phi_I.$
\end{itemize}
For example, when $k=1$, we have that $\cI = \langle (x_1 - y_1), (x_1-y_2), \ldots, (x_1-y_n) \rangle,$ so that
\[H_{T \times \C^\times}^*(\Gr(1,n)) \cong \Z[x_1, y_1, \ldots, y_n, h]^{S_k}/\cI\]

Now, for each $I \in \binom{[n]}{k}$, let $X_I^\circ = B_{-}\C^I,$ where $\C^I$ is the coordinate subspace spanned by $e_{I_1}, \ldots, e_{I_k},$ denote the Schubert cell corresponding to $I$. One can check that $X_I^\circ  \cong \C^{k(n-k)-\on{inv}(I)},$ where $\on{inv}(I)$ is the inversion number of the binary string corresponding to $I$. In particular, $X_I^\circ$ is smooth.

Let $C_I = \overline{\C_{X_I^\circ} \Gr(k, n)}$ denote the closure of the conormal bundle of $X_I^\circ$ in $T^*(\Gr(k,n)).$ Let $\Stil_I = [C_I] \in H_{T \times \C^\times}^*(X)$ be the fundamental class of this conormal bundle.

Recall that when examining $H_T^*(\Gr(\cdot, n)),$ the $T$-equivariant cohomology of $\bigsqcup_{k=1}^n \Gr(k,n),$ we assigned 
\[S_I \mapsto \bigotimes_{i=1}^n \begin{cases}
	\begin{pmatrix}
		1 & 0
	\end{pmatrix}^{Tr} & i \not \in I\\
	\begin{pmatrix}
		0 & 1
	\end{pmatrix}^{Tr} & i \in I
\end{cases}\]

In the case of the cotangent bundle, we attach an element of $(\C^2)^{\otimes n}$ to each $\Stil_I$ via \textbf{link patterns}. We begin with the binary string associated to $I$, and repeatedly attach links between each substring of $1 0$, ignoring previously linked letters. This is perhaps most easily illustrated with an example: if our binary string is $01101001$, the associated link pattern would be \ctikzfig{LinkPattern}
To the link \tikzfig{LinkPatternij} between positions $i$ and $j$, we associate
$\begin{pmatrix}
	1\\
	0
\end{pmatrix}_i
\otimes
\begin{pmatrix}
	0\\
	1
\end{pmatrix}_j
-
q^{-1}
\begin{pmatrix}
	0\\
	1
\end{pmatrix}_i
\otimes
\begin{pmatrix}
	1\\
	0
\end{pmatrix}_j,
$
while to a ``lonely" $0$ or $1$ in position $i$ we associate $\begin{pmatrix} 1\\ 0\end{pmatrix}_i$ and $\begin{pmatrix} 0\\ 1\end{pmatrix}_i$ respectively. We then take the tensor product over the vectors associated to all links/lonely elements. 

\begin{Theorem}[Z-J, \href{https://doi.org/10.3842/SIGMA.2018.069}{Loop Models and $K$-Theory}, 2016]
	$\Stil_I = [C_I]$ is equal to the loop model partition function on a $k \times n$ rectangle where the connectivity of the external points satisfy:
	\begin{itemize}
		\item No bottom points are connected to other bottom points
		\item No top points are connected to right points
		\item The top lines reproduce the link pattern of the associated binary string.
	\end{itemize}
\end{Theorem}

\section{Lecture 15 (Allen Knutson)}

\begin{Definition}
	Let $0 = n_0 \leq n_1 \leq n_2 \leq \dots \leq n_d \leq n_{d+1} = n$ be a sequence of integers, we define the Grothendieck-Springer space as
	\begin{equation*}
		\begin{aligned}
			\GS \coloneqq \{
			 & (\overrightarrow{\varepsilon} \in \C^d, V^* := (0 = V^{n_0} \subseteq V^{n_1} \subseteq V^{n_2} \subseteq \dots \subseteq V^{n_d} \subseteq V^{n_{d+1}}  =\C^n), X \in \End(\C^n)): \\
			 & \dim V^{n_i} = n_i, (X - \varepsilon_i) \cdot V^{n_i} \subseteq V^{n_{i-1}} \}
		\end{aligned}
	\end{equation*}
\end{Definition}

We think of $V^*$ as a partial flag and $n_i$ as its dimensions.

It is clear from the conditions that there is an action of $\GL_n(\C)$ on $\GS$ that preserves $\overrightarrow{\varepsilon}$, acts by multiplication on the flag $V^*$, and by conjugation on $X$.

\begin{Example}
	If we fix $V^*$ to be a standard partial flag, then the conditions imply that $X$ is a block matrix:
	\begin{equation*}
		\newcommand*{\tempb}{\multicolumn{1}{|c}{}}
		\newcommand*{\tempc}{\multicolumn{1}{c|}{}}
		X = \left[\begin{array}{cccccccc}
				\varepsilon_1    &        & \text{\large{0}} & \tempb        &        &        &                  &        \\
				                 & \ddots &                  & \tempb        &        &        & \text{\LARGE{*}} &        \\
				\text{\large{0}} &        & \varepsilon_1    & \tempb        &        &        &                  &        \\ \cline{1-5}
				                 &        & \tempc           & \varepsilon_2 & 0      & \tempb &                  &        \\
				                 &        & \tempc           & 0             & \ddots & \tempb &                  &        \\ \cline{4-5}
				                 &        &                  &               &        & \ddots &                  &        \\ \cline{7-8}
				                 &        & \text{\LARGE{0}} &               &        & \tempc & \varepsilon_d    & 0      \\
				                 &        &                  &               &        & \tempc & 0                & \ddots \\
			\end{array}\right]
	\end{equation*}
\end{Example}

\begin{Example}
	If we fix $\overrightarrow{\varepsilon} = \overrightarrow{0}$ then we have the isomorphism
	\[
		\GS|_{\overrightarrow{\varepsilon}=0} \cong \text{T}^* \Fl(n_1, \dots, n_d; \C^n).
	\]
\end{Example}

\begin{Example}
	Let $\overrightarrow{\varepsilon}$ be non-repeating, $n_i=i$ and $d=n$. Then we have
	\[
		X \in \GL_n(\C) \cdot
		\begin{bmatrix*}
			\varepsilon_1&&\text{\large{0}}\\
			&\ddots&\\
			\text{\large{0}}&&\varepsilon_n
		\end{bmatrix*}.
	\]
	Hence, the full flag $V^*$ is determined from $X$ by taking appropriate sums of the (one dimensional) eigenspaces,
	and we obtain that the fiber is the homogeneous space
	\[
		\GS|_{\overrightarrow{\varepsilon}} \cong \GL_n / T.
	\]
\end{Example}

\begin{Remark}
	In general, $\GS$ is a manifold.
	For any fixed ${\overrightarrow{\varepsilon}}$, it is still a manifold since it's a bundle over the flag manifold and the fibers are smooth.
\end{Remark}

\begin{Remark}
	If we fix ${\overrightarrow{\varepsilon}} = {\overrightarrow{0}}$ and forget the flag, then the image of $\GS|_{\overrightarrow{\varepsilon}=0}$ in $\End(\C^n)$ is the cone of nilpotent matrices, which is singular. This is what Springer thought about, taking $\GS|_{\overrightarrow{\varepsilon}=0}$ as a resolution of singularities of the nilpotent cone.
\end{Remark}

\begin{Remark}
	Outside of Type $A$, we can consider $\GS$ as well.
	We take $V^* \in G/P$, $X \in \Lie(G)^\vee$, $\overrightarrow{\varepsilon} \in Z(\text{Levi}(P))$ and one can figure out the appropriate conditions make it work.
\end{Remark}

Recall the Bruhat decomposition
\[
	G/B = \bigsqcup_{w \in W} B_- w B / B
\]

and consider the similar inclusion

\[
	G/T \supseteq \bigsqcup_{w \in W} B_- w T/T
\]

The action of $W = N(T)/T$ on $G/T$ by right-multiplication permutes the spaces $B_- w T/T$ transitively.

Looking at the simplest $B_- T/T$, it is closed in $G/T$ since $B_-$ is closed in $G$. Hence, \textbf{all} the spaces $B_- w T/T$ are closed and have the same dimension $\dim (B_- T/T) = \frac{1}{2} \dim (G/T)$.

In particular, this implies that the inclusion is strict unless $G$ is trivial.

\begin{Remark}
	This is very different from the Bruhat decomposition of $G/B$!
\end{Remark}

We wish to take the "limit" ${\overrightarrow{\varepsilon}} \to {\overrightarrow{0}}$ to get from $G/T$ to $\text{T}^* G/B$. Similarly, on the right, we wish to consider the "limit" of the graph of an action $r_\alpha \in W$. This should give us an auto-correspondence at $\overrightarrow{\varepsilon} = \overrightarrow{0}$.

Fix a reflection $r_\alpha \in W$ and consider its action on $\GS|_{\overrightarrow{\varepsilon}}$, we denote its graph by
\[
	\text{graph}(r_\alpha) \subseteq
	(\GS|_{\overrightarrow{\varepsilon}})^2 \subseteq \GS^2.
\]

By varying over \textbf{generic} (non-repeating) $\overrightarrow{\varepsilon}$ we can consider the set
\[
	\overline{
		\bigcup_{\overrightarrow{\varepsilon}\text{non-repeating}} \text{graph}(r_\alpha)
	}
	\subseteq \GS^2
\]

This closure is going to tell us what happens at $\overrightarrow{0}$, where we can extract the desired auto-correspondence $\subseteq \GS|_{\overrightarrow{\varepsilon}=0} \times \GS|_{\overrightarrow{\varepsilon}=0}$.

\begin{Example}
	To see this construction in action, we can consider $\C^\times$ acting by division on $\C$. Then, the graph of $t \in \C^\times$ is $\text{graph}(t) = \{ (x,y) : y = x/t\}$, so the corresponding set is
	\[
		\overline{
			\bigcup_{t\in \C^\times} \text{graph}(t)
		} =
		\overline{
			\{ (x,y,t) : y=x/t\}
		} = \{ (x,y,t) : t y=x\}.
	\]
	From this we get the limit of $t \to 0$ as $\{(x,y): x=0\}$.
\end{Example}

Recall that in our case, $\GS|_{\overrightarrow{\varepsilon}=0} = \text{T}^* \GL_n/B$, so by the limit correspondence, we obtain an action
\[
	H^*_{T \times \C^\times}(\text{T}^* \GL_n/B) \circlearrowleft r_i.
\]

Recall that
\[
	H^*_{T \times \C^\times}(\text{T}^* \GL_n/B) = \Z[x_1, \dots, x_n, y_1, \dots, y_n, \hbar] / \la p(x) = p(y) \text{ for } p \text{ symmetric} \ra
\]
so that the action of $r_i$ is algebraically given by the operator $r_i^x + \hbar \partial_i^x$ where $r_i^x$ swaps $x_i$ with $x_{i+1}$, and  $\partial_i^x = \frac{1}{x_i-x_{i+1}} (1-r_i^x)$. Note that $r_i$ is indeed an action since $r_i^2 = 1$.

In the following, we are interested in computing the classes of the limits of $B_- w T/T$ in $H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$. In fact, we need only consider one such class, since we know that the action of $W$ is transitive.

We start with the base case $w_0^{(n)}$ and consider the polynomial
\[
	\MO_{w_0^{(n)}} = S_{w_0^{(n)}} = \prod_{i+j\leq n} (x_i-y_j),
\] where $\MO$ stands for Maulik Okounkov, to obtain the general case
\[
	\MO_w = \left(\prod_{\text{reduced word for } w^{-1}w_0^{(n)}} (r_i + \hbar \partial_i)\right) \MO_{w_0^{(n)}}.
\]

As we did with double Schubert polynomials, we define the restriction to a point $v \in W$ by
\[
	\cdot\  |_v \coloneqq (x_i \mapsto y_{v(i)})
\]
so that $\MO_w |_v \in H_{T \times \C^\times}^*(\text{pt}) = \Z[y_1, \dots, y_n, \hbar]$.

In the following, we would like to see if the classes of the limits are a basis for $H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$.

\begin{Definition}
	Denote the limit of the space $B_-w T/T$ by
	\[
		(\MO \text{ "stable Lagrangian cycle"})_w \coloneqq \lim_{\varepsilon\to 0} B_-w T/T \subseteq \text{T}^* \GL_n/B.
	\]
\end{Definition}

Then, by restricting to every point of $W$ and comparing classes, we can conclude that

\begin{Theorem}
	\[
		[ (\MO \text{ "stable Lagrangian cycle"})_w ]  \mapsfrom \MO_w \in \mathbb{Z}[x_1,\dots,x_n, y_1, \dots, y_n, \hbar]
	\]
	where $[ (\MO \text{"stable Lagrangian cycle"})_w ] \in H^*_{T \times \C^\times}(\text{T}^* \GL_n/B)$.
\end{Theorem}

\begin{Definition}
	The opposite $\MO$ class of $w$ is given by
	\[
		(\MO^w =\ )\  \widetilde{\MO_w} \coloneqq w_0^{(n)} \cdot \MO_w
	\]
	where $w_0^{(n)}$ acts by $y_i \mapsto y_{n+1-i}$.
\end{Definition}

The classes $\MO_w$ and $\MO^w$ are dual in the sense that they are both classes of Lagrangian spaces in $\text{T}^* \GL_n/B$ which we can intersect and integrate in equivariant cohomology to get the expected duality (ignoring the non-compactness of $\text{T}^* \GL_n/B$, via fixed points).

Finally, comparing with the Schubert basis, the $\MO$ classes are a basis in the following sense:
\begin{Proposition}
	The classes $[\MO_w]$ are a basis over $\text{frac}(H^*_{T\times\C^*})$.
\end{Proposition}

\section{Lecture 16 (Allen Knutson)}

\subsection{Setup}
\hfill\\
Consider the diagonal embedding $\grass{k}{n}\xrightarrow{\Delta}\grass{k}{n}\times \grass{k}{n}$. Recall from Lecture 13 that any continuous map between varieties/manifolds gives the following commutative diagram in the category of correspondences
\begin{ccd}
 \grass{k}{n}\times \grass{k}{n} \ar[d, "graph(s)\times graph(s) ", swap]   \ar[r, "graph(\Delta)^T"] & \grass{k}{n}  \ar[d, "graph(s)"] \\
 T^*\grass{k}{n}\times T^* \grass{k}{n}\ar[r, "C_{graph(\Delta)^T}"] & T^*\grass{k}{n}
\end{ccd}
where composition is given by fiber product, $s: \grass{k}{n}\hookrightarrow T^*\grass{k}{n}$ is the inclusion of the zero section and given $A$ a correspondence in $M\times N$, $C_A$ is the conormal bundle of $A$ in $M\times N$. As it will turn out, we have a better understanding of $C_{graph(\Delta)^T}$ over $graph(\Delta)^T$. \\

Recall that given a correspondence $L\subset M\times N$ we have an induced map on (equivariant) cohomology\footnote{This should really be (equivariant) Borel-Moore homology but for smooth varieties Borel-Moore homology is isomorphic to cohomology via Poincare duality and $\grass{k}{n}$ is smooth.} $\beta_L: H^*(M)\to H^*(N)$ given by the pull-push construction, i.e.
\[  \beta_L(\alpha)=(\pi_N)_* ([L]\cup \pi^*_M([\alpha])) \]
Moreover one has that $\beta_{graph(f)}=H^*(f)$ and in particular we see that $\beta_{graph(s)}:H^*(\grass{k}{n})\to H^*(T^*\grass{k}{n})$ corresponds to multiplication by the Poincare dual of the zero section, so multiplication by 1 for ordinary cohomology. Also recall that the product in (equivariant) cohomology comes from the pullback map of $\Delta$. As such, the transpose/dual map in (equivariant) Borel-Moore homology is given by $\beta_{graph(\Delta)^T}$. Therefore commutativity of the above diagram tells us that the product in $H^*(\grass{k}{n})$ can be computed from the map
\[ \beta_{C_{graph(\Delta)^T}}:H^*( T^*\grass{k}{n})\otimes H^*(T^* \grass{k}{n} )\to H^*( T^*\grass{k}{n})  \]
Switching to $T\times \C^\times$ equivariant cohomology, the only thing that changes is that the class of the Poincare dual of the zero section is no longer trivial so that $\beta_{graph(s)}$ is no longer trivial. Thus if we know the structure constants for multiplication of the Maulik Okounkov classes in $H^*_{T\times \C^\times}( T^*\grass{k}{n})$, say
\[  [MO_\lambda]\cdot [MO_{\mu}]=\sum_\nu \widetilde{c^\nu_{\lambda \mu}} [MO_\nu] \]
it follows from commutativty of the diagram above that in $H^*_{T\times \C^\times}( \grass{k}{n})$ we have the formula
\[  \frac{[MO_\lambda]}{[s]}\cdot \frac{[MO_{\mu}]}{[s]}=\sum_\nu \widetilde{c^\nu_{\lambda \mu}} \frac{[MO_\nu]}{[s]} \]

\begin{Definition}
The Serge-Schwartz-MacPherson class associated to a sequence $\lambda$ is
\[ SSM_\lambda:= \frac{[MO_\lambda]}{[s]}  \]
\end{Definition}

One might think that the classes $SSM_\lambda$ correspond to Schubert classes, but notice that both $[MO_\lambda]$ and $[s]$ arise geometrically from classes of Langrangian subvarieties of $T^*\grass{k}{n}$ and so $SSM_\lambda$ has degree 0. However it will turn out that

\begin{Proposition}
Let $\mathrm{inv}(\lambda)$ be the number of inversions in the sequence $\lambda$. Then
\[  \underset{h\to 0}{\mathrm{lim}} \ h^{\mathrm{inv}(\lambda)} SSM_\lambda=S_\lambda \]
where $S_\lambda$ is the corresponding Schubert class associated to $\lambda$. 
\end{Proposition} 


Heruistically, this is saying that the Schubert classes are the 5 vertex limit of the Maulik Okounkov classes which correspond to the 6 vertex model. 

\subsection{Stable Envelope}
\label{stablesect}
\hfill\\
The reason why we have a better understanding of $C_{graph(\Delta)^T}$ is that it factors 
\begin{ccd}
T^*\grass{k}{n}\times T^*\grass{k}{n} \ar[rd,"senv", swap] \ar[rr, "C_{graph(\Delta)^T}"]& & T^*\grass{k}{n} \\
& T^* \fl(k, n+k; 2n) \ar[ur,"hr", swap] &
\end{ccd}
Let us first describe the first correspondence/map $senv$, the stable envelope. 

\begin{Definition}
Let $\C^\times$ act on a variety $M$. Then define
\[ \attr(M, \C^\times)=\set{ m\in M \left\vert \, \lim_{z\to 0} z \cdot m \textnormal{  exists} \right.} \]
and similarly define 
\[\attrl(M, \C^\times)=\set{ (m_\ell, m)\in M^{\C^\times}\times M \left\vert \, m_\ell=\lim_{z\to 0} z \cdot m \textnormal{  exists} \right.} \]
\end{Definition}


\begin{Remark}
If $M$ is compact, then $\attr(M)=M$. When $M$ is not compact then $\attr(M)$ can be quite small. For example, let $\C^\times$ act on $\C$ with weight $-1$. Then only the origin $(0,0)$ is in $\attr(M)$, the limit for everything else goes to infinity.  
\end{Remark}

\begin{Remark}
$\attrl(M, \C^\times)$ is a correspondence between $M^{\C^\times}$ and $M$, but isn't the one we are looking for because the map $\attrl(M, \C^\times)\to M$ need not be proper\footnote{And so there will be no pushforward map in Borel-Moore homology}! For example, let $\C^\times$ act on $\C\P^1$ by $z\cdot [a: b]=[za:b]$. $\C\P^1$ is compact, so $\attr(M)=M$. Moreover, one can check that the only fixed points are $[1:0]$ (north pole) and $[0:1]$ (south pole) and that $m_\ell=[0:1]$ for all points $m\in \C\P^1$ except the north pole. It follows that $\attrl(M, \C^\times)=\C\sqcup pt$ topologically, and this isn't compact and so the map $\attrl(M, \C^\times)\to M$ cannot be proper in this case.
\end{Remark}

\begin{Theorem}
\label{affinetheorem}
If $M$ is affine, then the map $\attrl(M, \C^\times)\to M$ is proper.
\end{Theorem}

The following example will be very important. 

\begin{Example}
Let 
$$M^\prime=\mathrm{GL}_n\cdot\begin{pmatrix}
\epsilon_1 I_{n_1} &  &  &  \\
& \epsilon_2 I_{n_2} & & \\
 &  & \ddots &  \\
 &  &  & \epsilon_d I_{n_d}
\end{pmatrix}$$ where $\mathrm{GL}_n$ acts by conjugation and all the $\epsilon_i$ are fixed distinct elements of $\C$. This is what the general fiber of the partial Grothendieck Springer resolution $\mathrm{GS}_{n_1, \ldots, n_d}$ looks like. Recall that
\[ M^\prime\cong \frac{\gl_n}{\gl_{n_1}\times \ldots \gl_{n_d}} \]
And as a result, $M$ will be an affine variety as it's the quotient of a reductive group acting on an affine variety. 
\end{Example}

Now, consider the case when $M=T^*\fl(k, n+k; 2n)$. This is not affine and so we can't use \cref{affinetheorem} to conclude that $\attrl(M, \C^\times)$ gives rise to a map in cohomology. However, recall that $M$ is the 0 fiber in the partial Grothendieck Springer resolution, i.e.
\[  \mathrm{GS}_{k, n+k}|_{\vec{\epsilon}=\vec{0}} = T^*\fl(k, n+k; 2n) \]

So $M$ in this case is the limit or special fiber of a family of varieties, most of which are affine by the example above (the set of points whose fibers are affine are dense). Therefore if we define 
\begin{Definition}
\[ env:=\lim_{\vec{\epsilon}\to \vec{0}} \  \attrl(T^*\fl(k, n+k; 2n), \C^\times ) \]
\end{Definition}
this will give rise to a map
\[ H^*(T^*\fl(k, n+k; 2n)^{\C^\times})\xrightarrow{\beta_{env}} H^*(T^*\fl(k, n+k; 2n)) \]

But what is $T^*\fl(k, n+k; 2n)^{\C^\times}$? Well, this will depend on the weights of the action of $\C^\times$ on $\C^{2n}$, but first consider an easier, related problem, namely $\grass{k}{V\oplus W}$ where $\C^\times$ acts on $V\oplus W$ with weights $0$ on $V$ and $1$ on $W$. Explicitly this means that $z\cdot(\vec{v}, \vec{w})=(\vec{v}, z\vec{w})$. Then because $\C^\times$ acts on $V$ and $W$ with different weights, we will have the following decomposition
\begin{equation}
\label{eq1}
\grass{k}{V\oplus W}^{\C^\times}=\bigsqcup_{i+j=k} \grass{i}{V}\times \grass{j}{W} 
\end{equation}  
One way to get an element of the LHS is the following procedure. Consider any subspace $A\subseteq V\oplus W$ and note that
\[ \lim_{z\to 0} z\cdot A=(\textnormal{Projection of }A \textnormal{ to }V)\oplus A\cap W``=" \mathrm{gr}(A) \]
The notation $\mathrm{gr}(A) $ is because we can think of the result as the associated graded subspace of $A$ under the filtration $0\subseteq W\subseteq V\oplus W$. By \cref{eq1} we see that the LHS above is in $\grass{k}{n}^{\C^\times}$. \\

Now let $V=\C^n$ and $W= \C^n$ and again let $\C^\times$ act on $V$ and $W$ with weights 0 and 1. The same reasoning giving rise to the decomposition in \cref{eq1} also applies to the two step partial flag variety, i.e. we will have the following decomposition
\[ \fl(k, n+k; 2n)^{\C^\times}= \bigsqcup_{\substack{a+c=k \\ b+d=n+k}} \fl(a,b ; n)\times \fl(c,d; n) \]
And notice that for $a=0, b=k$, we have that the RHS above will be
\[ \fl(0,k ; n)\times \fl(k, n ; n)=\grass{k}{n}\times \grass{k}{n} \]
$\grass{k}{n}\times \grass{k}{n}$ is one of the 
Now applying $T^*$ to everything, and since $T^*(\grass{k}{n}\times \grass{k}{n})\hookrightarrow T^* \fl(k, n+k; 2n)^{\C^\times}$ is closed it's also proper and so we obtain our desired map
\[ senv: H^*(T^*( \grass{k}{n})\times T^*(\grass{k}{n}) \, )\to H^*(T^*\fl(k, n+k; 2n)^{\C^\times})\xrightarrow{\beta_{env}} H^*(T^*\fl(k, n+k; 2n)) \] 

\subsection{Hamiltonian Reduction and Nakajima quiver varieties}

\begin{Definition}
Suppose that $G$ is a Lie group acting on symplectic manifold $M$ such that the action is Hamiltonian. Let $\mu: M\to \mathfrak{g}^*$ be the associated moment map and let $\lambda$ be a regular value of $\mu$. Then the symplectic reduction is defined to be $\mu^{-1}(\lambda)/G$. If $\lambda$ and $\mu$ are given, this will be abbreviated as $M//G$.
\end{Definition}

\begin{Theorem}[Marsden-Weinstein]
$M//G$ is a symplectic manifold. 
\end{Theorem}

\begin{Theorem}
If $G$ is compact, the quotient map $\pi: \mu^{-1}(\lambda)\to M//G$ is proper.
\end{Theorem}
\begin{proof}
We need to show that $\pi$ is closed with compact fibers. The fact that $\pi$ is closed reduces to the fact that when $G$ is compact, the $G-$orbit of a closed set is also a closed set. The fibers of $\pi$ are all of the form $G\cdot m$ where $m\in M$ which is diffeomorphic to $G/ G_m$ where $G_m$ is the stabilizer of $m$. Since $G$ is compact, and $G\to G / G_m$ is surjective and continuous, it follows that $G / G_m$ is also compact.  
\end{proof}

Thus when $G$ is compact, it follows from above that $\mu^{-1}(\lambda)\times M//G$ gives us a correspondence from $M$ to the symplectic reduction $M//G$ such that we get an induced map on Borel-Moore homology. Moreover, since $\lambda$ is a regular value, $\mu$ is a submersion at $\lambda$ and it follows that $\mu^{-1}(\lambda)$ has codimension $\dim \mathfrak{g}^*=\dim G$ in $M$. It follows that 
\begin{equation}
\label{dimeq}
\dim M//G=\dim \mu^{-1}(\lambda)-\dim G=\dim M-2\dim G
\end{equation}

We want to apply the formalism above to $M=T^*\fl(k, n+k; 2n)$ so we want to find a compact $G$ such that $M//G=T^*\grass{k}{n}$. First note that 
\[  \fl(k, n+k; 2n)\cong \frac{\gl_{2n}}{  P_{k,n,n-k}  }\qquad \qquad  \grass{k}{n}\cong \frac{\gl_n}{P_{k, n-k} } \]
where $P_{k,n,n-k}$ and $P_{k, n-k}$ are the parabolic subgroups corresponding to the partition $k+n+n-k$ of $2n$ and $k+n-k=n$ of $2n$ and $n$ respectively. As a result, one can then compute their dimensions by computing the dimensions of the tangent spaces resulting in
\[ \dim T^*\fl(k, n+k; 2n) = 2n^2+2k(n-k) \qquad \qquad \dim T^*\grass{k}{n}=2k(n-k) \]

By \cref{dimeq}, it follows that we should have $\dim G=n^2$. So where are we going to find a compact group of dimension $n^2$ acting on $T^*\fl(k, n+k; 2n)$? It turns out that both $T^*\fl(k, n+k; 2n)$ and $T^*\grass{k}{n}$ are Nakajima quiver varieties, and these come with natural actions of $``\gl(\vec{w})"$ on the ``framed" vertices. We won't define these varieties, but will say how these varieties are indexed. Given a Dynkin diagram $I$, construct the Nakajima diagram of $I$ by attaching a framed vertex hanging off each vertex of $I$. For example the Nakajima diagram for $A_4$ looks like 
$$
\tikz[script math mode,baseline=0]{
\node[framed] at (0,1) (w1) { }; 
\node[framed] at (1,1) (w2) { }; 
\node[framed] at (2,1) (w3) { }; 
\node[framed] at (3,1) (w4) { }; 
\node[gauged] at (0,0) (v1) { }; 
\node[gauged] at (1,0) (v2) { }; 
\node[gauged] at (2,0) (v3) { }; 
\node[gauged] at (3,0) (v4) { }; 
\draw (w1) -- (v1) -- (v2) -- (v3) -- (v4) -- (w4);
\draw (w2) -- (v2);
\draw (w3) -- (v3);
}
$$
Given a Nakajima diagram, by filling in the vertices and framed vertices of $I$ with natural numbers with natural numbers $\vec{w}=(w^i)_{i\in I}$ and $\vec{v}=(v^i)_{i\in I}$ , there is a procedure to turn this datum into an algebraic variety $\mathcal{M}(I, \vec{w}, \vec{v})$.  For example,
$$\mathcal{M}(A_1, (n), (k))=
\tikz[script math mode,baseline=0]{
\node[framed] at (0,1) (w1) {n }; 
 \node[gauged] at (0,0) (v1) {k }; 
\draw (w1) -- (v1);
}\ \raisebox{1.4ex}{$\cong T^*\grass{k}{n}$}
$$
We should note that if $w^i=0$ then we will not draw the framed vertex at $i$. In general if $n_1<\ldots<n_{d-1}<n_d$ then we will have that  
$$
\tikz[script math mode,baseline=0]{
\node[framed] at (0,1) (w1) { n}; 
\node[gauged] at (0,0) (v1) {n_d }; 
\node[gauged] at (1,0) (v2) { n_{d-1}}; 
\node[gauged] at (2,0) (v3) {\ldots }; 
\node[gauged] at (3,0) (v4) { n_1}; 
\draw (w1) -- (v1) -- (v2) -- (v3) -- (v4);
}\ \raisebox{1.4ex}{$\cong  T^*\fl(n_1, \ldots, n_d; n)$}
$$
In our case we will be working with the Nakajima quiver variety 
$$
\tikz[script math mode,baseline=0]{
\node[framed] at (0,1) (w1) { 2n}; 
\node[gauged] at (0,0) (v1) {n+k}; 
\node[gauged] at (1.3,0) (v2) { k}; 
\draw (w1) -- (v1) -- (v2);
}\ \raisebox{1.4ex}{$\cong  T^*\fl(k,  n+k; 2n)$}
$$
The framed vertex $\tikz[script math mode, baseline=(w1.base)]{
\node[framed] at (0,0) (w1) { 2n}; 
}$ has an action of $\gl_{2n}$. If we write $T^*\fl(k,  n+k; 2n)$ in Springer coordinates, e.g.
\[ T^*\fl(k,  n+k; 2n)=\set{(X, V^{n+k}\supset W^k)\, | \, X\in \mathrm{End}(\C^{2n}), \C^{2n}\xrightarrow{X} V^{n+k}\xrightarrow{X}W^k\xrightarrow{X} 0 } \]
where $V^{n+k}$ is a $n+k$ dimensional subspace of $\C^{2n}$ and $W^k$ is a $k$ dimensional subspace in $V^{n+k}$, then the action of $g\in \gl_{2n}$ is
\begin{equation}
\label{actioneq}
g\cdot( X, V^{n+k}\supset W^k)=(gxg^{-1}, g( V^{n+k})\supset g(W^k)) 
\end{equation}  
Inside $\gl_{2n}$ we have the unitary subgroup 
\[ U_n:=\left\{ \left.\begin{bmatrix}
I_n & 0 \\
E & I_n
\end{bmatrix} \right\vert  E\in \mathrm{Mat}_{n\times n}  \right\} \subseteq \gl_{2n}\]
which is a compact group of dimension $n^2$ so this fits our criteria from above. The moment map for the action of $U_n$ turns out to send $X$ to the northeast $n\times n$ quadrant of $X$ when written in block matrix form. We will let $\lambda=I_n$ and as a result we have that
\[  T^*\fl(k,  n+k; 2n)//U_n= \set{(X, V^{n+k}\supset W^k)\, \left \vert  X=\begin{bmatrix}
A & I_n \\
C & D
\end{bmatrix},  \C^{2n}\xrightarrow{X} V^{n+k}\xrightarrow{X}W^k\xrightarrow{X} 0 \right.} /U_n \]

\begin{Proposition}
\[  T^*\fl(k,  n+k; 2n)//U_n\cong T^*\grass{k}{n} \]
\end{Proposition}
\begin{proof}
The fiber of the moment map imposes more conditions on the set of tuples $(X, V, W)$ than described above. In particular, let $\vec{v}=(\vec{v_1} \ \vec{v_2})^T\in \ker X$. Then it follows from
\[ \begin{bmatrix}
A & I_n \\
C & D
\end{bmatrix}\begin{pmatrix}
\vec{v_1}\\
\vec{v_2}
\end{pmatrix}=\begin{pmatrix}
A\vec{v_1}+\vec{v_2}\\
C\vec{v_1}+D\vec{v_2}
\end{pmatrix} =\begin{pmatrix}
0 \\
0
\end{pmatrix}
\]
that $\vec{v_2}=-A\vec{v_1}$ and thus $(C-DA)\vec{v_1}=0$. We claim that $\dim \ker X\ge n$ from which it follows that $(C-DA)\vec{v_1}=0 \ \forall \vec{v_1}\in \C^n$ or in other words $C=DA$. Because $X$ preserves the flag, $X$ restricts to a map
\[  X|_V: V\to W \]
Because $\dim V=n+k$ and $\dim W=k$, by rank-nullity it follows that
\[ \dim \ker X|_V=(n+k)-\dim \mathrm{im } X|_V\ge (n+k)-k=n \]
and thus $C=DA$ as desired. In fact much more is true, as from before we know that
\[  \ker X \subseteq \set{\begin{bmatrix}
v \\
-Av
\end{bmatrix}, v\in \C^n}=V_0\]
and the subspace on the right has dimension $n$. Therefore 
$$\dim \ker X=\dim \ker X|_V=n\implies\ker X =V_0\subseteq V \textnormal{ and } \mathrm{im }X|_V=W $$
Another consequence of the moment map condition is that since $X^3=0$ we have
\[ X^3=\begin{bmatrix}
* & C+A^2+AD+D^2 \\
* & *
\end{bmatrix} = 0\]
As $C=DA$ the top right entry will be $(A+D)^2$ and so $(A+D)^2=0$. \\

We now consider the action of $U_n$. We claim that any element in 
$\mu^{-1}(I_n)$ is in the orbit of elements of the form
\[  \left( X=\begin{bmatrix}
0 & I_n \\
0 & F
\end{bmatrix} , \C^n\oplus M \supset X(M) \right) \]
Given $(X, V^{n+k}\supset W^k)\in \mu^{-1}(I_n)$, let $V^{\prime}:=(0\oplus \C^n)\cap V$. We claim that $ V=\ker X\oplus V^\prime $. The above description of $\ker X=V_0$ shows that $\ker X\cap V^\prime=\set{0}$ and it is easy to see that these two subspaces span $V$. From this we see that $X|_{V^\prime}$ gives an isomorphism $V^\prime\xrightarrow{\simeq}W$ and thus $W$ is extraneous data, as it can be recovered from $X$ and $V$. Let $g=\begin{bmatrix}
I_n & 0 \\
A & I_n
\end{bmatrix}$. By the definition of the action \cref{actioneq} one can compute that
\[ g\cdot(X, V)=g\cdot \paren{ \begin{bmatrix}
A & I_n\\
DA & D
\end{bmatrix} , \ker X\oplus V^\prime }=  \paren{ \begin{bmatrix}
0 & I_n\\
0 & A+D
\end{bmatrix} , \C^n\oplus V^\prime}\]
which is exactly of the form above. Now, the RHS only depends on the datum of $A+D$ and $V^\prime$ and we claim that they in fact satisfy the conditions to be in $T^*\grass{k}{n}$. As $(A+D)^2=0$ from above, we only need to check that $(A+D)v\in V^\prime\ \forall v\in \C^n$. This follows from $V_0\subset V$ and so 
\[ \begin{pmatrix}
0 \\
(A+D)v
\end{pmatrix}=\begin{pmatrix}
v \\
Dv
\end{pmatrix}-\begin{pmatrix}
v \\
-Av
\end{pmatrix}\in V \]
\end{proof}

\subsection{Finale}


As explained in the paragraph before \cref{dimeq}, the Hamiltonian reduction now gives us a correspondence
\[ hr:  T^*\fl(k,  n+k; 2n)\to  T^*\grass{k}{n}   \]
and as alluded to at the beginning of \cref{stablesect} we have the following theorem

\begin{Theorem}[\href{https://arxiv.org/pdf/2102.00563.pdf}{Knutson, Zinn-Justin, 2021}]
  The two Lagrangian correspondences $senv,hr$
  $$
  \tikz[script math mode,baseline=0]{\dOne{k}{0} 
    \node[framed] at (1,1) (w1) {n}; \draw (v1) -- (w1);}
  \quad\times\quad
  \tikz[script math mode,baseline=0]{\dOne{n}{k} 
    \node[framed] at (1,1) (w1) {n}; \draw (v1) -- (w1);}
  \quad \xrightarrow{senv}
  \phantom{   \prod\limits_{i=1}^{n} }
  \tikz[script math mode,baseline=0]{\dOne{n+k}{k} 
    \node[framed] at (1,1) (w1) {2n}; \draw (v1) -- (w1);} 
  \quad  \xrightarrow{hr} % \xrightarrow{///_{I_n} U}
  \quad
  \tikz[script math mode,baseline=0]
  {
    \node[gauged] at (1,0) (v1) {k}; 
    \node[gauged] at (2,0) (v2) {k}; \draw (v1) -- (v2);
    \node[framed] at (2,1) (w2) {n}; \draw (v2) -- (w2);
  }
  $$
  can be composed. Under the identification of first and third spaces
  with $T^* \grass{k}{n}^2$ and $T^* \grass{k}{n}$, 
  the composite is the transpose $C_{graph(\Delta)^T}$ of 
  the conormal bundle of the graph of the diagonal inclusion.
\end{Theorem}

We should note that in order to make the identifications with $T^* \grass{k}{n}$ we are using the following theorem of Nakajima,

\begin{Theorem}[\href{https://link.springer.com/article/10.1007/s00208-003-0467-0}{Nakajima, 2003}] Let $i\in I$,  define 
$$r_i(\vec{v})^j:= \begin{cases}
  \vec{v}^j & \textnormal{ if }j\neq i\\
  \textnormal{sum of all adjacent labels }-\vec{v}^i & \textnormal{ if }j=i
\end{cases}
  $$
Then 
\[  \mathcal{M}(I, \vec{w}, \vec{v})\cong  \mathcal{M}(I, \vec{w}, r_i(\vec{v})) \]
    as complex varieties, equivariantly w.r.t.\ the framing group action
    $\prod_{i\in I} GL(w^i)$ on both sides. \\
\end{Theorem}
Applying Nakajima's theorem above we find that 
\[   \tikz[script math mode,baseline=0]{\dOne{n}{k} 
    \node[framed] at (1,1) (w1) {n}; \draw (v1) -- (w1);}\ \raisebox{1.7ex}{$\cong$} \ \tikz[script math mode,baseline=0]{\dOne{k}{k} 
    \node[framed] at (1,1) (w1) {n}; \draw (v1) -- (w1);}\ \raisebox{1.7ex}{$\cong$} \ \tikz[script math mode,baseline=0]{\dOne{k}{0} 
    \node[framed] at (1,1) (w1) {n}; \draw (v1) -- (w1);} \qquad \qquad   \tikz[script math mode,baseline=0]
  {
    \node[gauged] at (1,0) (v1) {k}; 
    \node[gauged] at (2,0) (v2) {k}; \draw (v1) -- (v2);
    \node[framed] at (2,1) (w2) {n}; \draw (v2) -- (w2);
  } \ \raisebox{1.7ex}{$\cong$} \ \tikz[script math mode,baseline=0]
  {
    \node[gauged] at (1,0) (v1) {0}; 
    \node[gauged] at (2,0) (v2) {k}; \draw (v1) -- (v2);
    \node[framed] at (2,1) (w2) {n}; \draw (v2) -- (w2);
  }\]
\begin{Remark}
We can actually write out the two correspondences very explicitly in Springer coordinates
\begin{gather*}
senv := \left\{ \left(
    (A,V',D,W'),
    \left(X,V,W\right)\right)
  \ :\
  X = \begin{pmatrix} D & * \\ 0 & A \end{pmatrix}, 
  \begin{array}[c]{ccc} V &=& \C^n \oplus V'\\
    W &=& W'\oplus 0  \end{array}
  \right\} 
\\
\begin{matrix}
  \swarrow &&\searrow \\ \\
  \{(A \in \mathrm{End}(\C^n), V'^{\ j})\} \times  \{(D \in \mathrm{End}(\C^n), W'^{\ j})\}
  &\qquad\qquad&
  \left\{ \left(X \in  \mathrm{End}(\C^{2n}), V^{n+j}, W^j \right) \right\}
\end{matrix}
\end{gather*}

$$ 
hr := \left\{ \left((X,V,W),(Y,V'') \right)  \ :\ 
  \begin{array}[c]{c}
    X = \begin{pmatrix} A & Id \\ DA & D \end{pmatrix}, \   Y = A+D\\
    \begin{array}{rcl}
      V \cap (0\oplus \C^n) &=& 0 \oplus V'' \\
      W / (0\oplus \C^n) &=& (W' + \C^n)/(0\oplus \C^n)
    \end{array}
  \end{array}
\right\}   
$$
$$
\begin{matrix}
  \swarrow &&\searrow \\
  \left\{ \left(X \in  \mathrm{End}(\C^{2n}), V^{n+j}, W^j \right) \right\}
  &\qquad\qquad&
  \{(Y \in  \mathrm{End}(\C^n), V''^{\ j})\} 
\end{matrix}
$$

\end{Remark}

\section{Lecture 17 (Paul Zinn-Justin)}

\section{Lecture 18 (Paul Zinn-Justin)}

\end{document}
